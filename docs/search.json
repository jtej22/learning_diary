[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Josiah’s Remote Sensing Learning Diary",
    "section": "",
    "text": "Self-Introduction\nWelcome to my learning diary on remote sensing! I am currently a MSc Urban Spatial Science student at UCL Centre for Advanced Spatial Analytics (CASA). Prior to this, I graduated from UCL with a BSc in Geography with Economics. I am mainly interested in using spatial analysis techniques to urban problems from a policymaking perspective, which explains why I am at CASA now. After graduation, I will be working with Housing Development Board (HDB) in Singapore, the key agency responsible for public housing in the country. I have also interned with Singapore’s Ministry of Sustainability and Environment before, and am interested in urban environmental issues. Before my undergraduate studies, I also had a brief stint in the Singapore Armed Forces Mapping Unit where I had some exposure to satellite imagery and digitizing maps. I hope to learn necessary and relevant skills and techniques that can be applied to both urban housing and environmental contexts."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Boone, R. B., Thirgood, S. J. and Hopcraft, J. G. C. (2006)\n‘Serengeti wildebeest migratory patterns modeled from rainfall and\nnew vegetation growth’, Ecology, 87(8), pp. 1987–1994.\nAvailable at: https://www.jstor.org/stable/20069184.\n\n\nBuiten, H. J. and Putten, B. van (1997) ‘Quality assessment of\nremote sensing image registration  analysis and testing of\ncontrol point residuals’, ISPRS Journal of Photogrammetry and\nRemote Sensing, 52(2), pp. 57–73. doi: 10.1016/S0924-2716(97)83001-8.\n\n\nCorcione, V. et al. (2021) ‘A Sensitivity Analysis on the\nSpectral Signatures of Low-Backscattering Sea Areas in Sentinel-1 SAR\nImages’, Remote Sensing, 13(6), p. 1183. doi: 10.3390/rs13061183.\n\n\nFaridatul, M. I. and Ahmed, B. (2020) ‘Assessing Agricultural\nVulnerability to Drought in a Heterogeneous Environment: A Remote\nSensing-Based Approach’, Remote Sensing, 12(20), p.\n3363. doi: 10.3390/rs12203363.\n\n\nFensholt, R. and Proud, S. R. (2012) ‘Evaluation of Earth\nObservation based global long term vegetation trends \nComparing GIMMS and MODIS global NDVI time series’, Remote\nSensing of Environment, 119, pp. 131–147. doi: 10.1016/j.rse.2011.12.015.\n\n\nJensen, J. R. (2015) Introductory Digital Image Processing: A Remote\nSensing Perspective. Pearson Education, Incorporated.\n\n\nKlonus, S. and Ehlers, M. (2009) ‘2009 12th international\nconference on information fusion’, in, pp. 1409–1416.\n\n\nNovak, K. (1992) ‘Rectification of Digital Imagery’,\nPHOTOGRAMMETRIC ENGINEERING.\n\n\nPinto, D. G. et al. (2017) ‘Correlations between spectral\nand biophysical data obtained in canola canopy cultivated in the\nsubtropical region of Brazil’, Pesquisa Agropecuária\nBrasileira, 52(10), pp. 825–832. doi: 10.1590/s0100-204x2017001000001.\n\n\nPratt, W. (2013) Introduction to Digital Image Processing. Boca\nRaton: CRC Press. Available at: https://learning.oreilly.com/library/view/introduction-to-digital/9781482216691/.\n\n\nTucker, C. J. et al. (2005) ‘An extended AVHRR\n8-km NDVI dataset compatible with MODIS and SPOT vegetation\nNDVI data’, International Journal of Remote Sensing,\n26(20), pp. 4485–4498. doi: 10.1080/01431160500168686.\n\n\nWolberg, G. (1990) Digital image warping | wiley. New York:\nJohn Wiley- IEEE Computer Society. Available at: https://www.wiley.com/en-us/Digital+Image+Warping-p-9780818689444."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Week 2: Quarto and Xaringan",
    "section": "",
    "text": "https://jtej22.github.io/w2_presentation/presentation.html#1"
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "",
    "text": "{r, echo = FALSE, out.width=‘40%’} xaringanExtra::embed_xaringan( url = “link”, ratio = “16:9”)"
  },
  {
    "objectID": "week1.html#learning-objectives",
    "href": "week1.html#learning-objectives",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.1 Learning Objectives",
    "text": "1.1 Learning Objectives\nThe learning objectives of both the lecture and practical are:\n\nUnderstand the science behind remote sensors and how satellite imagery is obtained\nUnderstand how remotely sensed data work\nSource, load and articulate the differences between Landsat and Sentinel data\nUndertake basic raster image statistics and processing\nEvaluate the (dis)advantages of each type of software you have used\nPull out and statistically compare spectral signatures"
  },
  {
    "objectID": "week1.html#summary-of-key-concepts",
    "href": "week1.html#summary-of-key-concepts",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.2 Summary of key concepts",
    "text": "1.2 Summary of key concepts\n\n1.2.1 Types of sensors\nThere are 2 main types of sensors, passive and active sensors. The key difference is that passive sensors (e.g. cameras, satellite sensors) usually detect reflected energy from the Sun while active sensors (e.g. LiDAR, radar, X-Ray) actively emit electromagnetic (EM) waves and detected the reflected waves.\nThis difference will be useful as the usefulness of the data from different types of sensors will be affected. Passive sensors which rely on reflected energy are thus dependent on the Sun, meaning that the time and day the image is captured will affect the imagery’s usefulness, as well as if there’s presence of cloud cover as clouds will be captured too. This may render the images less useful and users have to use images from another recorded day. Active sensors are more able to bypass clouds and this means that their recorded data is usually not affected by cloud cover and more useful. This also ties into the scientific concept of EM waves, as active sensors record data from a wider range of the EM spectrum compared to passive sensors, hence it can “see” through clouds and other atmospheric conditions.\n\n\n1.2.2 Data resolutions\nThe 4 types of resolutions are:\n\nSpatial: Size of the raster grid per pixel\nSpectral: Number of bands it records data in\nTemporal: Frequency of revisiting the site\nRadiometric: Differences in light or reflectance"
  },
  {
    "objectID": "week1.html#practical",
    "href": "week1.html#practical",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.3 Practical",
    "text": "1.3 Practical\nThe practical gave me the opportunity to explore the differences between Sentinel and Landsat data, as well as go through the practical process of searching for and downloading the relevant datasets. While I am slightly clearer on the general process, I am still perplexed by the vast options available such as choosing platforms, product types, and what is the best practice for choosing relevant imagery for different purposes.\nWhen exploring the Sentinel data it was helpful to see the various bands and that solidified my understanding of spectral bands practically.\n\n\n\n\n\nFig. 1: Bands available in Sentinel data\n\n\n\n\n\n1.3.1 Colour composites\nColour composites are a way of manipulating the way rasters are visualised (not actually modifying the raster data) so that we can focus on different aspects. The RGB image allows us to see the raster data in a way that is intuitive. There are other composites (band combinations) that are useful such as:\n\nFalse colour (Color infrared) composite: Emphasizes vegetation health, with denser vegetation appearing red while urban areas appear white\n\nThis is because vegetation absorbs red\n\nAtmospheric penetration composite: does not use visible bands so as to not be affected by atmospheric particles\n\nVegetation appears blue, urban area appears white, gray cyan or purple.\n\nShortwave infrared composite: Used to illustrate vegetation in different shades of green (differing densities) and brown areas represent built up or bare soil.\nMore information can be found on gisgeography\n\n\n\n1.3.2 Scatterplot analysis\nWe were exposed to a really cool method of using scatterplots to statistically analyse images, and created a plot of Band 8 (y-axis) against Band 4 (x-axis).\nFor this practical, my city of choice was Cape Town, South Africa, which was the city Andy used in the practical instructions. I chose this city as I wanted to focus on familiarising with the layout and tools in SNAP and R and not worry about differences in inputs from Andy’s example.\nThe scatterplot I obtained is as follows:\n\n\n\n\n\nFig. 2: Tasseled Cap using Cape Town imagery\n\n\n\n\nThis scatterplot can be interpreted as follows:\n\n\n\n\n\nFig. 3: Interpretation of Tasseled Caps\n\n\n\n\nSource: Remote Sensing 4113\n\n\n1.3.3 Resampling and Masking\nResampling and Masking are essential processes when dealing with raster data.\nMasking is essentially clipping like what we saw in CASA0005, and this can be done with vector data (ESRI Shapefile .shp) in SNAP.\nResampling is the change of spatial resolution (either increasing or decreasing) of the raster dataset. Resampling calculates new pixel values from the original pixel values in the original image.\nThere are various resampling techniques:\n\nNearest Neighbour Resampling\n\nTakes the cell centre from the input raster to determine the closes cell centre of the output\nFastest method because of its simplicity\nIdeal for categorical, nominal and ordinal data as it does not alter values\nE.g. useful for landcover classification raster grid\n\nBilinear Interpolation\n\nCalculates values of a grid based on 4 nearby grids\nAssigns the output cell value by taking a weighted average\nUseful when working with continuous datasets that do not have distinct boundaries\nE.g. useful for noise distance rasters\n\nCubic Convolution Interpolation\n\nSimilar to bilinear interpolation\nUses 16 nearest cells instead\nLong processing time\nUsually used for continuous surfaces where much noise exists\n\nMajority Resampling\n\nSimilar to nearest neighbour algorithm\nInstead uses the most common values in a filter window\n\n\n\n\n1.3.4 Spectral Signatures\nComparing Landsat and Sentinel products, we only focus on overlapping bands which are B2-4.\nIn R, we use the shapefiles for each landcover type to extract pixel values from the raster data. This is done using the R package terra. As with CASA0005, it is important to check the CRS of our data. We use terra’s extract function to extract values from our raster, and we repeat this for each landcover type for each image type (Landsat and Sentinel).\nUsing these values, we plot spectral profiles and density plots to observe differences between landcover types.\n\n\n\n\n\nFig. 4a: Sentinel Spectral Reflectance\n\n\n\n\n\n\n\n\n\nFig. 4b: Landsat Spectral Reflectance\n\n\n\n\nComparing the two outputs, we firstly see that the Landsat plot only has 3 land-cover types as there was no high-urban POI in the Landsat file (due to differences in areas covered). The number of bands plotted is the number of bands that are available in the product. Ideally, we want each landcover type to have a distinct signature at each band so that we can use the raster products for landuse classification.\nFor both plots, there isn’t much of a distinct spectral signature any of the landcover types, and there is a fair amount of overlap between the landcover types in each band. This means that the raster products used are not the most ideal for landcover classification and more image processing might be needed. It should also be noted that while the Landsat plot looks less differentiated, the mean values on the y-axis are of different scales from the y-axis values for the Sentinel plot."
  },
  {
    "objectID": "week1.html#applications-of-spectral-signatures",
    "href": "week1.html#applications-of-spectral-signatures",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.4 Applications of Spectral Signatures",
    "text": "1.4 Applications of Spectral Signatures\nAn interesting application of spectral signatures in academic studies is the analysis of the effects of low-backscattering areas of anthropogenic and natural origin on the azimuth autocorrelation function (AACF) using VV-polarised SAR measurements (Corcione et al., 2021). This is of great interest for the marine pollution community to better differentiate between natural low-backscattering or human pollution."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.5 Reflection",
    "text": "1.5 Reflection\n\n1.5.1 Reflection on data resolutions\nSpatial and temporal resolution are concepts that are fairly straightforward to me, as I used to be a mapper with the Singapore Armed Forces, where both types of resolutions were practical considerations when we were digitising areas of interest as it affected how clearly we could observe features and when choosing image files to use.\nSpectral resolution was of particular interest to me, as it is the key area that is involved in remote sensing analysis. Objects appear as a certain colour on satellite imagery because that is the wavelength that is reflected, and in the raster data from remote sensors, we can observe values for each wavelength across the EM spectrum. This allows us to create a spectral signature which helps us identify different features or land-covers. This concept is explored more practically later.\nRadiometric resolution is the ability of a sensor to detect and record differences in energy, and the higher radiometric resolution a sensor has, the more sensitive it is to differences on the ground. This means the image is of better quality.\n\n\n1.5.2 POIs\nJust a note on POIs, while the practical suggested various land-cover types such as bare earth, water grass, forest and urban, I interpreted these land-cover types according to my prior experience of landcover classification in Singapore. This meant I did not find any suitable POIs for the forest category as it was mostly bare earth, grass and farmland in the tile. Upon clarification with Andy, the main takeaway is that POIs depend on the area chosen and research objectives, and what types of landcover are present. It is up to the researcher to define the classifications.\nWe can also rely on landcovers classified by other researchers such as Dynamic World and reference their 9 land use and cover types (e.g. trees, grass, shrub & scrub and snow & ice)\n\n\n1.5.3 Spectral Signatures\nSpectral signatures will be key in my remote sensing journey moving forward. Regarding resources for spectral signatures that might be useful in the future, there is the USGS Spectral Library where we can reference the spectral reflectance of various materials for identification purposes. There is also the Awesome Spectral Indices list which keeps track of classical and novel spectral indices for different Remote Sensing applications."
  },
  {
    "objectID": "week1.html#references",
    "href": "week1.html#references",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.6 References",
    "text": "1.6 References\n\n\n\n\n\n\n\nCorcione, V. et al. (2021) “A Sensitivity Analysis on the Spectral Signatures of Low-Backscattering Sea Areas in Sentinel-1 SAR Images,” Remote Sensing, 13(6), p. 1183. doi: 10.3390/rs13061183."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Week 3: Corrections",
    "section": "",
    "text": "Understand and apply types of corrections that can be applied to remotely sensed data\nUnderstand and apply methods of data joining and enhancement\nUnderstand how enhancements can be used to emphasize certain features or spectral traits"
  },
  {
    "objectID": "week3.html#summary-of-key-concepts",
    "href": "week3.html#summary-of-key-concepts",
    "title": "3  Week 3: Corrections",
    "section": "3.2 Summary of Key Concepts",
    "text": "3.2 Summary of Key Concepts\n\n3.2.1 Overview\nIn this lecture, we mainly looked at types of corrections that could be applied to remotely sensed data:\n\nGeometric\n\nUse Ground Control Points (GCPs) to match points in the new image to a reference dataset.\nIdeally done with backward mapping (output to input) so that we can get a value in the original input image for every value in the gold standard (Jensen, 2015, p. 247).\nAnd resample the final raster\n\nAtmospheric\n\nRelative (e.g. Dark Object Subtraction or Pseudo-Invariant Features)\nAbsolute; using atmospheric radiative transfer models, assuming atmospheric measurements are available (e.g. Py6S)\n\nOrthorectification/ Topographic Correction\n\nRemoving distortions such that the pixels viewed at nadir (straight down)\nRequires sensor geometry and DEM.\nCosine correction can be used (Jensen, 2015)\n\nRadiometric\n\nUsing Digital Number to obtain spectral radiance\n\n\nWe also looked at how remotely sensed data can be mosaicked and enhanced. Mosaicking is the process of joining 2 or more images together, similar to merging in the sense of polygons.\nTypes of Enhancements and methods:\n\nContrast enhancement:\n\nMinimum-Maximum\nPercentage Linear and Standard Deviation\nPiecewise Linear Contrast Stretch\n\nBand Ratioing\nFiltering\nPrincipal Component Analysis (PCA)\n\n\n\n3.2.2 Geometric Corrections and Mosaicking (Jensen, 2015)\nFor this week’s learning diary, I will be focusing on types of geometric corrections and the mosaicking process, based on Jensen’s textbook (2015).\nGround Control Points are locations on the road surface that can be easily and accurately identified on a map. Each GCP should have 2 distinct sets of coordinates, image and map coordinates.\nImage-to-map rectification\nThis is the process by which the geometry of an image is made planimetric, to remove distortion caused by topographic relief displacement.\nSteps:\n\nSpatial Interpolation: The geometric relationship between input pixel coordinates and reference map coordinates must be identified, to establish the nature of transformation to be applied to all other pixels.\n\nUnsystematic errors in the new image produced by changes in attitude (roll, pitch and yaw) or altitude\nA first-order, six-parameter, linear transformation is sufficient to rectify the imagery to a geographic frame of reference.\nThis type of transformation can model 6 kinds of distortions (Novak, 1992; Buiten and Putten, 1997)\n\nTranslation in x and y\nScale changes in x and y\nSkew\nRotation\n\nForward Mapping (input-to-output):\n\n\\[\nx = a_0 + a_1 x' + a_2 y'\n\\]\n\\[\ny = b_0 + b_1 x' + b_2 y'\n\\]\nThis forward mapping logic is useful when we rectify the location of discrete coordinates along a linear feature. However, when we are filling a rectified output grid with values from an unrectified input image, forward mapping logic is not very useful as the output location may not fall exactly on a x,y output map coordinate.\nThis can result in output matrix pixels with no output values (Wolberg, 1990)\n\nInverse Mapping (output-to-input)\n\n\\[\nx' = a_0 + a_1 x + a_2 y\n\\]\n\\[\ny' = b_0 + b_1 x + b_2 y\n\\]\nThe rectified output matrix is filled systematically, with the equation using the six coefficient to determine where to get a value from the original input image. Here, nearest-neighbour resampling logic is used.\nA quadratic polynomial can also be used for transformations, but this is usually only used when there are serious geometric errors, usually in imagery obtained from suborbital aerial platforms.\n\\[\nx' = c_0 + c_1x + c_2y + c_3xy + c_4x^2 + c_5y^2\n\\]\n\\[\ny' = d_0 + d_1x + d_2y + d_3xy + d_4x^2 + d_5y^2\n\\]\nComputing the Root-Means-Squared-Error of the Inverse Mapping Function\nUsing RMSE allows us to determine how well the 6 coefficients derived from the least-squares regression of the initial GCPs account for the geometric distortion in the input image.\nThe user specifies a threshold of acceptable total RSME, and the GCP with the most individual error will be deleted, then recompute the 6 coefficients and RMSE for all points, until the RMSE is less than the threshold or there are too few GCPs remaining for a regression.\n\n\nIntensity Interpolation: Pixel brightness values should be determined. When a pixel in the rectified output image requires a value from the input pixel that does not fall neatly on a row-and-column coordinate, there must be a mechanism for determining the Brightness Value (BV) to be assigned to the output rectified pixel.\n\nSeveral methods of Brightness Value interpolation including nearest neighbour, bilinear interpolation and cubic convolution\nNearest neighbour is computationally efficient and does not alter BVs during resampling. It should be used when biophysical information is to be extracted from the dataset.\nBilinear interpolation assigns pixel values by interpolating BVs in 2 orthogonal directions, computing a new BV based on weighted distances to the nearest 4 pixel values. This method acts as a spatial moving filter that subdues extremes in BVs in the output image.\nCubic convolution assigns values similarly to bilinear interpolation, except that weighted values of 16 input pixels are used.\n\n\nImage-to-image registration\nThis is the translation and rotation alignment process by which 2 images of similar geometry and of same geographic area are positioned coincident to each other so that corresponding elements appear in the same place. This is used when it is not necessary to have each pixel assigned a unique x,y coordinate. A hybrid approach that uses both image-to-map rectification and image-to-image registration might be useful when detecting change between 2 or more dates of remotely sensed data."
  },
  {
    "objectID": "week3.html#summary-of-practical",
    "href": "week3.html#summary-of-practical",
    "title": "3  Week 3: Corrections",
    "section": "3.3 Summary of Practical",
    "text": "3.3 Summary of Practical\nThis practical covered basic correction concepts such as atmospheric correction, mosaicking and enhancements. For this practical, I decided to look at Landsat8 imagery of Serengeti National Park (SNP) in Tanzania. I will be summarising my takeaways from the mosaicking and ratio enhancement sections of the practical, as I found them to be particularly useful. I was also unable to perform the PCA section as it took too long for my computer.\n\n3.3.1 Mosaicking\nFor SNP, 3 tiles were needed to have a fuller view of the whole national park, so I downloaded 3 tiles that covered most of it. The first image shows the extent covered by the downloaded tiles, while the second shows the mosaicked output from R.\n\n\n\n\n\nFig. 1: Extent of tiles\n\n\n\n\n\n\n\n\n\nFig. 2: Mosaicked output\n\n\n\n\nThe mosaicked output in R was written to a GeoTiff file and then viewed in QGIS. It appears slightly off but I am unsure what went wrong in the process or this is an expected outcome.\n\n\n3.3.2 Ratio enhancements: NDVI\nThe Normalised Difference Vegetation Index is an application of ratioing, based on the fact that green vegetation absorbs the Red wavelength but reflects more in the NIR wavelength. This is illustrated as:\n\n\n\n\n\nFig. 3: Spectral traits of vegetation\n\n\n\n\nSource: PhysicsOpenLab\n\\[\nNDVI =  \\frac{NIR - Red}{NIR + Red}\n\\]\nApplying the NDVI formula to my dataset, I obtained first\n\n\n\n\n\nFig. 4: NDVI of Serengeti National Park\n\n\n\n\nWe can also focus on areas where NDVI is equal or greater than 0.1:\n\n\n\n\n\nFig. 5: NDVI of Serengeti National Park 2\n\n\n\n\nWe observe that the vegetation is not as healthy as we might expect, and this is because the images used were between 24/10/22 and 31/12/22 which coincides with the drier period.\nThis also coincides with the visualisations obtained when using the Normalised Difference Moisture Index (NDMI) and focusing on areas where NDMI is equal or greater than 0.1:\n\n\n\n\n\nFig. 6: NDMI of Serengeti National Park\n\n\n\n\n\n\n\n\n\nFig. 7: NDMI of Serengeti National Park2\n\n\n\n\nData fusion is the process of appending new raster data to existing datasets or creating new raster datasets with different bands, and data fusion can be done with newly-created texture measures and the original data. Fusion can be done in R using the stack() function.\nWhen merging datasets obtained from different remote sensors, all datasets should be accurately registered to one another and resampled to the same pixel size. One component-substitution method available is Principle Component Analysis (PCA). At this stage I would have done Principal Component Analysis to scale the raster datasets, but unfortunately I was unable to complete the PCA part of the practical. PCA allows comparison of data that is not easily comparable in its raw form. Performing PCA would transform the original data to produce uncorrelated principal component images (Pratt, 2013). An advantage of PCA-based pan-sharpening is that the number of bands is not restricted (Klonus and Ehlers, 2009)"
  },
  {
    "objectID": "week3.html#applications-of-ratio-enhancements",
    "href": "week3.html#applications-of-ratio-enhancements",
    "title": "3  Week 3: Corrections",
    "section": "3.4 Applications of Ratio Enhancements",
    "text": "3.4 Applications of Ratio Enhancements\nThe normalised difference vegetation index (NDVI) is widely used for vegetation studies, with the NASA Global Inventory, Monitoring and Modelling Studies (GIMMS) global coverage dataset (Tucker et al., 2005) being the most widely used AVHRR (Advanced Very High Resolution Radiometer) dataset. They form a relatively robust basis for detecting long-term trends in NDVI in most of the world’s semi-arid, dry sub-humid and sub-humid areas (Fensholt and Proud, 2012).\nNDVI values can be used to determine and analyse drought-prone areas, such as Faridatul and Ahmed’s (2020) work incorporating NDVI values into a modified vegetation condition index (mVCI) which enhances the detection of agricultural drought in the study area of Bangladesh; or can be used to analyse crop yields based on Pinto et al.’s (2017) work on canola yields in Brazil.\nFocusing on Serengeti National Park, I thought it would be useful to use NDVI on satellite imagery of SNP for potential applications of monitoring anthropogenic impacts on the Protected Area or impacts of climate change on the ecosystem. For example, Boone et al (2006) use rainfall and vegetation data (and NDVI) to model Serengeti wildebeest migratory patterns. However, Anderson et al (anderson?) also make the point that we should be cautious when using NDVI to study wildlife hotspots as NDVI can represent the effects of multiple, correlated processes (e.g. biomass, forage quality, cover for predators etc.) that influence the presence of hotspots (e.g. herbivore hotspots)."
  },
  {
    "objectID": "week3.html#reflections",
    "href": "week3.html#reflections",
    "title": "3  Week 3: Corrections",
    "section": "3.5 Reflections",
    "text": "3.5 Reflections\nAs Andy mentioned in the lectures, it is unlikely that we would have to perform geometric corrections given that most datasets are “Analysis Ready Data” (ARD), but it is useful to know in the event that we encounter data that requires geometric correction, or even just understanding how the data products we use have been treated from their raw form.\nMosaicking is a useful process given the limitations of some remote sensing products regarding geographical extents, and might come in handy in future research. Nonetheless, Andy also mentioned how this process may not be as important today as it is incorporated in the Google Earth Engine (GEE) workflow, so I am excited to learn in future weeks how this process is done in GEE. Mosaicking is also a bit of a throwback personally, back to 2017-18 for me when I learnt how to orthorectify and mosaic in ERDAS Imagine software (which I realised I have forgotten most of by now) and I am excited to learn how the process has evolved today when we start using GEE.\n\n\n\n\nBoone, R. B., Thirgood, S. J. and Hopcraft, J. G. C. (2006) “Serengeti wildebeest migratory patterns modeled from rainfall and new vegetation growth,” Ecology, 87(8), pp. 1987–1994. Available at: https://www.jstor.org/stable/20069184.\n\n\nBuiten, H. J. and Putten, B. van (1997) “Quality assessment of remote sensing image registration  analysis and testing of control point residuals,” ISPRS Journal of Photogrammetry and Remote Sensing, 52(2), pp. 57–73. doi: 10.1016/S0924-2716(97)83001-8.\n\n\nFaridatul, M. I. and Ahmed, B. (2020) “Assessing Agricultural Vulnerability to Drought in a Heterogeneous Environment: A Remote Sensing-Based Approach,” Remote Sensing, 12(20), p. 3363. doi: 10.3390/rs12203363.\n\n\nFensholt, R. and Proud, S. R. (2012) “Evaluation of Earth Observation based global long term vegetation trends  Comparing GIMMS and MODIS global NDVI time series,” Remote Sensing of Environment, 119, pp. 131–147. doi: 10.1016/j.rse.2011.12.015.\n\n\nJensen, J. R. (2015) Introductory Digital Image Processing: A Remote Sensing Perspective. Pearson Education, Incorporated.\n\n\nKlonus, S. and Ehlers, M. (2009) “2009 12th international conference on information fusion,” in, pp. 1409–1416.\n\n\nNovak, K. (1992) “Rectification of Digital Imagery,” PHOTOGRAMMETRIC ENGINEERING.\n\n\nPinto, D. G. et al. (2017) “Correlations between spectral and biophysical data obtained in canola canopy cultivated in the subtropical region of Brazil,” Pesquisa Agropecuária Brasileira, 52(10), pp. 825–832. doi: 10.1590/s0100-204x2017001000001.\n\n\nPratt, W. (2013) Introduction to Digital Image Processing. Boca Raton: CRC Press. Available at: https://learning.oreilly.com/library/view/introduction-to-digital/9781482216691/.\n\n\nTucker, C. J. et al. (2005) “An extended AVHRR 8-km NDVI dataset compatible with MODIS and SPOT vegetation NDVI data,” International Journal of Remote Sensing, 26(20), pp. 4485–4498. doi: 10.1080/01431160500168686.\n\n\nWolberg, G. (1990) Digital image warping | wiley. New York: John Wiley- IEEE Computer Society. Available at: https://www.wiley.com/en-us/Digital+Image+Warping-p-9780818689444."
  },
  {
    "objectID": "week3.html#references",
    "href": "week3.html#references",
    "title": "3  Week 3: Corrections",
    "section": "3.6 References",
    "text": "3.6 References\n\n\n\nAnderson, T. M., J. G. C. Hopcraft, S. Eby, M. Ritchie, J. B. Grace, H. Olff (2010) ‘Landscape-scale analyses suggest both nutrient and antipredator advantages to Serengeti herbivore hotspots’, Ecology, 91(5), 1519-29.\nBoone, R. B., S. J. Thirgood, J. G. C. Hopcraft (2006) ‘Serengeti Wildebeest Migratory Patterns Modeled from Rainfall and New Vegetation Growth’, Ecology, 87(8), 1987-94.\nBuiten, H. J. and B. Van Putten (1997) ‘Quality Assessment of Remote Sensing Registration- Analysis and Testing of Control Point Residuals’, ISPRS Journal of Photogrammetry & Remote Sensing, 52, 57-73. Available at: https://doi.org/10.1016/S0924-2716(97)83001-8\nFaridatul, M. I. and B. Ahmed (2020) ‘Assessing Agricultural Vulnerability to Drought in a Heterogeneous Environment: A Remote Sensing-Based Approach’, Remote Sensing, 12(20), 3363.\nFensholt, R. and S. R. Proud (2012) ‘Evaluation of Earth Observation based global long term vegetation trends — Comparing GIMMS and MODIS global NDVI time series’, Remote Sensing of Environment, 119, 131-47.\nJensen, J.R. (2015) Introductory Digital Image Processing, 4th edn, Pearson Higher Education US (A Remote Sensing Perspective).\nKlonus, S. and M. Ehlers (2009) ‘Performance of Evaluation Methods in Image Fusion’, Proceedings of the 12th International Conference on Information Fusion, Seattle, July 6-9 2009, p. 8.\nNovak, K. (1992) ‘Rectification of Digital Imagery’, Photogrammeric Engineering & Remote Sensing, 58(3), 339-44.\nPinto, D. G., D. C. Fontana, G. A. Damalgo, E. Fochesatto, M. B. Vicari, C. Bremm, G. R. da Cunha, J. A. de Gouvea, A. Santi (2017) ‘Correlations between spectral and biophysical data obtained in canola canopy cultivated in the subtropical region of Brazil’, Pesquisa Agropecuária Brasileira, 52 (10), 825-32.\nPratt, W. K. (2013) Introduction to Digital Image Processing, Boca Raton: CRC Press, p. 736.\nTucker, C. J., J. E. Pinzon, M. E. Brown, D. A. Slayback, E. W. Pak, R. Mahoney (2005) ‘An extended AVHRR 8-km NDVI dataset compatible with MODIS and SPOT vegetation NDVI data’, International Journal of Remote Sensing, 26, 4485-98.\nWolberg, G. (1990) Digital Image Warping, NY: John Wiley- IEEE Computer Society, p. 340.\n\n\n\n\nBoone, R. B., Thirgood, S. J. and Hopcraft, J. G. C. (2006) “Serengeti wildebeest migratory patterns modeled from rainfall and new vegetation growth,” Ecology, 87(8), pp. 1987–1994. Available at: https://www.jstor.org/stable/20069184.\n\n\nBuiten, H. J. and Putten, B. van (1997) “Quality assessment of remote sensing image registration  analysis and testing of control point residuals,” ISPRS Journal of Photogrammetry and Remote Sensing, 52(2), pp. 57–73. doi: 10.1016/S0924-2716(97)83001-8.\n\n\nFaridatul, M. I. and Ahmed, B. (2020) “Assessing Agricultural Vulnerability to Drought in a Heterogeneous Environment: A Remote Sensing-Based Approach,” Remote Sensing, 12(20), p. 3363. doi: 10.3390/rs12203363.\n\n\nFensholt, R. and Proud, S. R. (2012) “Evaluation of Earth Observation based global long term vegetation trends  Comparing GIMMS and MODIS global NDVI time series,” Remote Sensing of Environment, 119, pp. 131–147. doi: 10.1016/j.rse.2011.12.015.\n\n\nJensen, J. R. (2015) Introductory Digital Image Processing: A Remote Sensing Perspective. Pearson Education, Incorporated.\n\n\nKlonus, S. and Ehlers, M. (2009) “2009 12th international conference on information fusion,” in, pp. 1409–1416.\n\n\nNovak, K. (1992) “Rectification of Digital Imagery,” PHOTOGRAMMETRIC ENGINEERING.\n\n\nPinto, D. G. et al. (2017) “Correlations between spectral and biophysical data obtained in canola canopy cultivated in the subtropical region of Brazil,” Pesquisa Agropecuária Brasileira, 52(10), pp. 825–832. doi: 10.1590/s0100-204x2017001000001.\n\n\nPratt, W. (2013) Introduction to Digital Image Processing. Boca Raton: CRC Press. Available at: https://learning.oreilly.com/library/view/introduction-to-digital/9781482216691/.\n\n\nTucker, C. J. et al. (2005) “An extended AVHRR 8-km NDVI dataset compatible with MODIS and SPOT vegetation NDVI data,” International Journal of Remote Sensing, 26(20), pp. 4485–4498. doi: 10.1080/01431160500168686.\n\n\nWolberg, G. (1990) Digital image warping | wiley. New York: John Wiley- IEEE Computer Society. Available at: https://www.wiley.com/en-us/Digital+Image+Warping-p-9780818689444."
  },
  {
    "objectID": "week1.html#refs",
    "href": "week1.html#refs",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.6 References",
    "text": "1.6 References\n\n\n\n\nCorcione, Valeria, Andrea Buono, Ferdinando Nunziata, and Maurizio Migliaccio. 2021. “A Sensitivity Analysis on the Spectral Signatures of Low-Backscattering Sea Areas in Sentinel-1 SAR Images.” Remote Sensing 13 (6, 6): 1183. https://doi.org/10.3390/rs13061183."
  },
  {
    "objectID": "week1.html#section",
    "href": "week1.html#section",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.6 ",
    "text": "1.6 \n\n\n\n\nCorcione, V. et al. (2021) “A Sensitivity Analysis on the Spectral Signatures of Low-Backscattering Sea Areas in Sentinel-1 SAR Images,” Remote Sensing, 13(6), p. 1183. doi: 10.3390/rs13061183."
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  Week 4: Policy",
    "section": "",
    "text": "Singapore is a tropical city-state located in Southeast Asia, and is well-known for being a “Green City” for its extensive incorporation of greenery into its urban form. In light of climate change and the need to transit to more sustainable forms of development, the Singapore government launched the Singapore Green Plan 2030in 2021 to drive the national agenda on sustainable development. As a low-lying island state, climate change is an existential threat for Singapore and there is a need to ensure its resilience to climate threats. There are 5 key pillars to the Singapore Green Plan (SGP):\n\nCity in Nature\n\nKey Goal: Set aside 50% more land (200 ha) for nature parks, intensify nature in gardens and parks, and for every household to live within 10 minutes walk of a park\n\nEnergy Reset\n\nKey Goals: Quadruple solar energy deployment by 2025, including covering rooftops of state-subsidised housing blocks with solar panels, and reduce domestic greenhouse gas emissions by at least 3 million tonnes per year by 2030.\n\nSustainable Living\n\nKey Goals: Reduce waste sent to landfills by 30% and encourage walking and cycling as transport options.\n\nGreen Economy\n\nKey Goals: Promote Green Finance and carbon trading\n\nResilient Future\n\nKey Goals: Better understand and protect coastlines against rising sea levels, and limit the urban heat island effect.\n\n\nFor the policy goals of protecting coastlines and limiting urban heat effects, it is admirable that Singapore is looking to incorporate remotely sensed data into its workflow for achieving these goals. To better understand and model rising sea levels and their effects on Singapore, the Public Utilities Board (PUB) has collaborated with National University of Singapore (NUS) to use remotely-sensed data and geospatial models. As for efforts mitigating Urban Heat Island effect, the National Parks agency (NParks) has deployed an island-wide network of climate sensors that collect data on wind speeds, humidity and temperature. The collected data will then be used in the Singapore Variable Resolution (SINGV) model (which models future climatic scenarios) and the Integrated Environment Modeller (IEM) (which helps urban planners optimise building layouts).\nRemote sensing data can be further incorporated into the the Singapore Green Plan workflow, and I would propose using it to help in the achievement of the City in Nature goal."
  },
  {
    "objectID": "week4.html#application-of-remotely-sensed-data-to-the-city-in-nature-goal",
    "href": "week4.html#application-of-remotely-sensed-data-to-the-city-in-nature-goal",
    "title": "4  Week 4: Policy",
    "section": "4.2 Application of remotely sensed data to the City in Nature goal",
    "text": "4.2 Application of remotely sensed data to the City in Nature goal\nI would propose the use of remote sensing methods to measure and track the intensity of nature in gardens and parks.\nBefore I go into the details of how this can be done specifically in Singapore’s context, I will first do a literature review on current methodologies on urban vegetation.\nFor this, I refer to Neyns and Canters’ (2022) overview on current literature on urban vegetation in remote sensing. Scholars either define vegetation types based on functionality or taxonomic classes. Studies that analyse vegetation type by functionality tend to focus on the provision of ecosystem services., while classification by species in the urban environment tends to be more challenging due to noise.\nAs for the type of sensor data, it is noted that high spatial resolution (which is desirable to ensure that the vegetation is larger than a pixel) usually comes with a tradeoff on spectral resolution (which is better for mapping results). As for spectral bands, Li et al (2015)] found that the newly added red edge and NIR2 bands of Worldview 2 and 3 contribute more to the differentiation of tree species compared to the traditional four bands of Worldview 1 (red, green, blue, NIR). The mapping of individual trees becomes easier from a resolution of 3m or higher, and both spaceborne and airborne sensors can produce imagery at this resolution. Degerickx et al (2020) also found that structural variables derived from LiDAR data was more useful than hyperspectral variables. Using multi-temporal data is also useful to assess the influence of the time of data acquisition as well as in the classification process. However, given the relative stability of Singapore’s weather throughout the year, this may not be as essential.\nAs for feature definition, there are several types discussed such as spectral, textural, geometric, contextual and LIDAR-derived features. Spectral features use vegetation indices such as NDVI (which was covered in week 3), although NDVI in urban environments may lead to the possible false labelling of red clay roofs as vegetation (Zhang, Feng and Jiang, 2010). Geometric features describing the size, shape and edge complexity of objects can be useful in identifying broader functional vegetation types due to their widely different spatial properties (i.e. the space they occupy). Contextual features use neighbouring characteristics, and can be used for the mapping of functional vegetation types, such as Wen et al. (2017) differentiating between road-side, park and residential trees by considering the relation between trees in a predefined area.\nWang et al (2019) concluded that fusion of spectral imagery with Light Detection And Ranging (LiDAR) data substantially improves the identification of tree species in a urban setting. Authors also deal with shadows in various ways such as omitting elements affected by shadow, or by performing shadow correction, or by including shadowed areas as separate classes.\nReferring to Ren et al’s (2017) work, we see that using NDVI with Landsat TM data is also useful in rapdily estimating urban vegetation structural attributes such as leaf area index (LAI), crown closure (CC) and basal area (BA) at a spatiotemporal 30m resolution. NDVI applied to Sentinel-2 images, combined with plant height information (using Digital Object Height Models) is also another method of analysing he spatial distribution of well-equipped greenspace areas with high health and recreational potential as well as areas for improvement in poorly-equipped urban areas (Juergens and Meyer-Heß, 2022).\nCircling back to how Singapore can use remote sensing methods to plan and monitor greenspaces and vegetation intensity, I would propose using Landsat or Sentinel imagery with NDVI, combined with 3D datasets to analyse greenspaces and plan where improvements in greenspaces should occur based on Juergens and Meyer-Heß’s (2022)methodology. Following which, I propose that remote sensing methods also be incorporated into a monitoring process, to measure the change in vegetation intensity and if planned improvements to urban vegetation are successful. Given that this measurement is not needed frequently (probably once a year), I would recommend that airborne sensors be used, so that data of high spatial and spectral resolution can be gathered, making the measurement of urban vegetation intensity more accurate. LiDAR data should also be included so that it can be combined with spectral imagery. This will allow Singapore to more easily quantify and measure the effectiveness of their efforts to intensify urban vegetation in its goal to become a City in Nature."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Week 4: Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nThinking about policy applications was helpful as it pushed me to consider the specific data sources and methodologies that could be used to achieve particular goals, and this was helpful as we could think through specific details rather than just “know” that remotely sensed data could be applied in different many ways. Obviously, there are more ways we can think about the practical applications of remotely sensed data in policy, but I enjoyed this start. While I now roughly understand the steps that can be taken to apply remote sensing methodologies in a policy context, I think the next step is to understand how I can actually do it practically, which I look forward to learning more about in the rest of the module.\n\n\n\n\nDegerickx, J., Hermy, M. and Somers, B. (2020) “Mapping Functional Urban Green Types Using High Resolution Remote Sensing Data,” Sustainability, 12(5), p. 2144. doi: 10.3390/su12052144.\n\n\nJuergens, C. and Meyer-Heß, M. F. (2022) “Experimental Analysis of Geo-spatial Data to Evaluate Urban Greenspace: A Case Study in Dortmund, Germany,” KN - Journal of Cartography and Geographic Information, 72(2), pp. 153–171. doi: 10.1007/s42489-022-00107-5.\n\n\nLi, D. et al. (2015) “Object-Based Urban Tree Species Classification Using Bi-Temporal WorldView-2 and WorldView-3 Images,” Remote Sensing, 7(12), pp. 16917–16937. doi: 10.3390/rs71215861.\n\n\nNeyns, R. and Canters, F. (2022) “Mapping of Urban Vegetation with High-Resolution Remote Sensing: A Review,” Remote Sensing, 14(4), p. 1031. doi: 10.3390/rs14041031.\n\n\nRen, Z. et al. (2017) “Spatiotemporal analyses of urban vegetation structural attributes using multitemporal Landsat TM data and field measurements,” Annals of Forest Science, 74(3), pp. 1–14. doi: 10.1007/s13595-017-0654-x.\n\n\nWang, K., Wang, T. and Liu, X. (2019) “A Review: Individual Tree Species Classification Using Integrated Airborne LiDAR and Optical Imagery with a Focus on the Urban Environment,” Forests, 10(1), p. 1. doi: 10.3390/f10010001.\n\n\nWen, D. et al. (2017) “Semantic classification of urban trees using very high resolution satellite imagery,” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 10(4), pp. 1413–1424. doi: 10.1109/JSTARS.2016.2645798.\n\n\nZhang, X., Feng, X. and Jiang, H. (2010) “Object-oriented method for urban vegetation mapping using IKONOS imagery,” International Journal of Remote Sensing, 31(1), pp. 177–196. doi: 10.1080/01431160902882603."
  }
]