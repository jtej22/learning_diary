[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Josiah’s Remote Sensing Learning Diary",
    "section": "",
    "text": "Self-Introduction\nWelcome to my learning diary on remote sensing! I am currently a MSc Urban Spatial Science student at UCL Centre for Advanced Spatial Analytics (CASA). Prior to this, I graduated from UCL with a BSc in Geography with Economics. I am mainly interested in using spatial analysis techniques to urban problems from a policymaking perspective, which explains why I am at CASA now. After graduation, I will be working with Housing Development Board (HDB) in Singapore, the key agency responsible for public housing in the country. I have also interned with Singapore’s Ministry of Sustainability and Environment before, and am interested in urban environmental issues. I hope to learn necessary and relevant skills and techniques that can be applied to both urban housing and environmental contexts."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "4  Summary",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Week 2: Quarto and Xaringan",
    "section": "",
    "text": "https://jtej22.github.io/w2_presentation/presentation.html#1"
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "",
    "text": "{r, echo = FALSE, out.width=‘40%’} xaringanExtra::embed_xaringan( url = “link”, ratio = “16:9”)"
  },
  {
    "objectID": "week1.html#learning-objectives",
    "href": "week1.html#learning-objectives",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.1 Learning Objectives",
    "text": "1.1 Learning Objectives\nThe learning objectives of both the lecture and practical are:\n\nUnderstand the science behind remote sensors and how satellite imagery is obtained\nUnderstand how remotely sensed data work\nSource, load and articulate the differences between Landsat and Sentinel data\nUndertake basic raster image statistics and processing\nEvaluate the (dis)advantages of each type of software you have used\nPull out and statistically compare spectral signatures"
  },
  {
    "objectID": "week1.html#summary-of-key-concepts",
    "href": "week1.html#summary-of-key-concepts",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.2 Summary of key concepts",
    "text": "1.2 Summary of key concepts\n\n1.2.1 Types of sensors\nThere are 2 main types of sensors, passive and active sensors. The key difference is that passive sensors (e.g. cameras, satellite sensors) usually detect reflected energy from the Sun while active sensors (e.g. LiDAR, radar, X-Ray) actively emit electromagnetic (EM) waves and detected the reflected waves.\nThis difference will be useful as the usefulness of the data from different types of sensors will be affected. Passive sensors which rely on reflected energy are thus dependent on the Sun, meaning that the time and day the image is captured will affect the imagery’s usefulness, as well as if there’s presence of cloud cover as clouds will be captured too. This may render the images less useful and users have to use images from another recorded day. Active sensors are more able to bypass clouds and this means that their recorded data is usually not affected by cloud cover and more useful. This also ties into the scientific concept of EM waves, as active sensors record data from a wider range of the EM spectrum compared to passive sensors, hence it can “see” through clouds and other atmospheric conditions.\n\n\n1.2.2 Data resolutions\nThe 4 types of resolutions are:\n\nSpatial: Size of the raster grid per pixel\nSpectral: Number of bands it records data in\nTemporal: Frequency of revisiting the site\nRadiometric: Differences in light or reflectance"
  },
  {
    "objectID": "week1.html#practical",
    "href": "week1.html#practical",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.3 Practical",
    "text": "1.3 Practical\nThe practical gave me the opportunity to explore the differences between Sentinel and Landsat data, as well as go through the practical process of searching for and downloading the relevant datasets. While I am slightly clearer on the general process, I am still perplexed by the vast options available such as choosing platforms, product types, and what is the best practice for choosing relevant imagery for different purposes.\nWhen exploring the Sentinel data it was helpful to see the various bands and that solidified my understanding of spectral bands practically.\n\n\n\n\n\nFig. 1: Bands available in Sentinel data\n\n\n\n\n\n1.3.1 Colour composites\nColour composites are a way of manipulating the way rasters are visualised (not actually modifying the raster data) so that we can focus on different aspects. The RGB image allows us to see the raster data in a way that is intuitive. There are other composites (band combinations) that are useful such as:\n\nFalse colour (Color infrared) composite: Emphasizes vegetation health, with denser vegetation appearing red while urban areas appear white\n\nThis is because vegetation absorbs red\n\nAtmospheric penetration composite: does not use visible bands so as to not be affected by atmospheric particles\n\nVegetation appears blue, urban area appears white, gray cyan or purple.\n\nShortwave infrared composite: Used to illustrate vegetation in different shades of green (differing densities) and brown areas represent built up or bare soil.\nMore information can be found on gisgeography\n\n\n\n1.3.2 Scatterplot analysis\nWe were exposed to a really cool method of using scatterplots to statistically analyse images, and created a plot of Band 8 (y-axis) against Band 4 (x-axis).\nFor this practical, my city of choice was Cape Town, South Africa, which was the city Andy used in the practical instructions. I chose this city as I wanted to focus on familiarising with the layout and tools in SNAP and R and not worry about differences in inputs from Andy’s example.\nThe scatterplot I obtained is as follows:\n\n\n\n\n\nFig. 2: Tasseled Cap using Cape Town imagery\n\n\n\n\nThis scatterplot can be interpreted as follows:\n\n\n\n\n\nFig. 3: Interpretation of Tasseled Caps\n\n\n\n\nSource: Remote Sensing 4113\n\n\n1.3.3 Resampling and Masking\nResampling and Masking are essential processes when dealing with raster data.\nMasking is essentially clipping like what we saw in CASA0005, and this can be done with vector data (ESRI Shapefile .shp) in SNAP.\nResampling is the change of spatial resolution (either increasing or decreasing) of the raster dataset. Resampling calculates new pixel values from the original pixel values in the original image.\nThere are various resampling techniques:\n\nNearest Neighbour Resampling\n\nTakes the cell centre from the input raster to determine the closes cell centre of the output\nFastest method because of its simplicity\nIdeal for categorical, nominal and ordinal data as it does not alter values\nE.g. useful for landcover classification raster grid\n\nBilinear Interpolation\n\nCalculates values of a grid based on 4 nearby grids\nAssigns the output cell value by taking a weighted average\nUseful when working with continuous datasets that do not have distinct boundaries\nE.g. useful for noise distance rasters\n\nCubic Convolution Interpolation\n\nSimilar to bilinear interpolation\nUses 16 nearest cells instead\nLong processing time\nUsually used for continuous surfaces where much noise exists\n\nMajority Resampling\n\nSimilar to nearest neighbour algorithm\nInstead uses the most common values in a filter window\n\n\n\n\n1.3.4 Spectral Signatures\nComparing Landsat and Sentinel products, we only focus on overlapping bands which are B2-4.\nIn R, we use the shapefiles for each landcover type to extract pixel values from the raster data. This is done using the R package terra. As with CASA0005, it is important to check the CRS of our data. We use terra’s extract function to extract values from our raster, and we repeat this for each landcover type for each image type (Landsat and Sentinel).\nUsing these values, we plot spectral profiles and density plots to observe differences between landcover types.\n\n\n\n\n\nFig. 4a: Sentinel Spectral Reflectance\n\n\n\n\n\n\n\n\n\nFig. 4b: Landsat Spectral Reflectance\n\n\n\n\nComparing the two outputs, we firstly see that the Landsat plot only has 3 land-cover types as there was no high-urban POI in the Landsat file (due to differences in areas covered). The number of bands plotted is the number of bands that are available in the product. Ideally, we want each landcover type to have a distinct signature at each band so that we can use the raster products for landuse classification.\nFor both plots, there isn’t much of a distinct spectral signature any of the landcover types, and there is a fair amount of overlap between the landcover types in each band. This means that the raster products used are not the most ideal for landcover classification and more image processing might be needed. It should also be noted that while the Landsat plot looks less differentiated, the mean values on the y-axis are of different scales from the y-axis values for the Sentinel plot."
  },
  {
    "objectID": "week1.html#applications-of-spectral-signatures",
    "href": "week1.html#applications-of-spectral-signatures",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.4 Applications of Spectral Signatures",
    "text": "1.4 Applications of Spectral Signatures\nAn interesting application of spectral signatures in academic studies is by Corcione et al (2021) which analyses the effects of low-backscattering areas of anthropogenic and natural origin on the azimuth autocorrelation function (AACF) using VV-polarised SAR measurements. This is of great interest for the marine pollution community to better differentiate between natural low-backscattering or human pollution."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.5 Reflection",
    "text": "1.5 Reflection\n\n1.5.1 Reflection on data resolutions\nSpatial and temporal resolution are concepts that are fairly straightforward to me, as I used to be a mapper with the Singapore Armed Forces, where both types of resolutions were practical considerations when we were digitising areas of interest as it affected how clearly we could observe features and when choosing image files to use.\nSpectral resolution was of particular interest to me, as it is the key area that is involved in remote sensing analysis. Objects appear as a certain colour on satellite imagery because that is the wavelength that is reflected, and in the raster data from remote sensors, we can observe values for each wavelength across the EM spectrum. This allows us to create a spectral signature which helps us identify different features or land-covers. This concept is explored more practically later.\nRadiometric resolution is the ability of a sensor to detect and record differences in energy, and the higher radiometric resolution a sensor has, the more sensitive it is to differences on the ground. This means the image is of better quality.\n\n\n1.5.2 POIs\nJust a note on POIs, while the practical suggested various land-cover types such as bare earth, water grass, forest and urban, I interpreted these land-cover types according to my prior experience of landcover classification in Singapore. This meant I did not find any suitable POIs for the forest category as it was mostly bare earth, grass and farmland in the tile. Upon clarification with Andy, the main takeaway is that POIs depend on the area chosen and research objectives, and what types of landcover are present. It is up to the researcher to define the classifications.\nWe can also rely on landcovers classified by other researchers such as Dynamic World and reference their 9 land use and cover types (e.g. trees, grass, shrub & scrub and snow & ice)\n\n\n1.5.3 Spectral Signatures\nSpectral signatures will be key in my remote sensing journey moving forward. Regarding resources for spectral signatures that might be useful in the future, there is the USGS Spectral Library where we can reference the spectral reflectance of various materials for identification purposes. There is also the Awesome Spectral Indices list which keeps track of classical and novel spectral indices for different Remote Sensing applications."
  },
  {
    "objectID": "week1.html#references",
    "href": "week1.html#references",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.6 References",
    "text": "1.6 References\nCorcione, V. A. Buono, F. Nunziata and M. Migliaccio (2021) ‘A Sensitivty Analysis on the Spectral Signatures of Low-Backscattering Sea Areas in Sentinel-1 SAR Images’, Remote Sensing, 13(6), 1183; https://doi.org/10.3390/rs13061183."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Week 3: Corrections",
    "section": "",
    "text": "Understand and apply types of corrections that can be applied to remotely sensed data\nUnderstand and apply methods of data joining and enhancement\nUnderstand how enhancements can be used to emphasize certain features or spectral traits"
  },
  {
    "objectID": "week3.html#summary-of-key-concepts",
    "href": "week3.html#summary-of-key-concepts",
    "title": "3  Week 3: Corrections",
    "section": "3.2 Summary of Key Concepts",
    "text": "3.2 Summary of Key Concepts\n\n3.2.1 Overview\nIn this lecture, we mainly looked at types of corrections that could be applied to remotely sensed data:\n\nGeometric\n\nUse Ground Control Points (GCPs) to match points in the new image to a reference dataset.\nIdeally done with backward mapping (output to input) so that we can get a value in the original input image for every value in the gold standard (Jensen 2015:247).\nAnd resample the final raster\n\nAtmospheric\n\nRelative (e.g. Dark Object Subtraction or Pseudo-Invariant Features)\nAbsolute; using atmospheric radiative transfer models, assuming atmospheric measurements are available (e.g. Py6S)\n\nOrthorectification/ Topographic Correction\n\nRemoving distortions such that the pixels viewed at nadir (straight down)\nRequires sensor geometry and DEM.\nCosine correction can be used (Jensen 2015)\n\nRadiometric\n\nUsing Digital Number to obtain spectral radiance\n\n\nWe also looked at how remotely sensed data can be mosaicked and enhanced. Mosaicking is the process of joining 2 or more images together, similar to merging in the sense of polygons.\nTypes of Enhancements and methods:\n\nContrast enhancement:\n\nMinimum-Maximum\nPercentage Linear and Standard Deviation\nPiecewise Linear Contrast Stretch\n\nBand Ratioing\nFiltering\nPrincipal Component Analysis (PCA)\n\n\n\n3.2.2 Geometric Corrections and Mosaicking (Jensen 2015)\nFor this week’s learning diary, I will be focusing on types of geometric corrections and the mosaicking process, based on Jensen’s textbook (2015).\nGround Control Points are locations on the road surface that can be easily and accurately identified on a map. Each GCP should have 2 distinct sets of coordinates, image and map coordinates.\nImage-to-map rectification\nThis is the process by which the geometry of an image is made planimetric, to remove distortion caused by topographic relief displacement.\nSteps:\n\nSpatial Interpolation: The geometric relationship between input pixel coordinates and reference map coordinates must be identified, to establish the nature of transformation to be applied to all other pixels.\n\nUnsystematic errors in the new image produced by changes in attitude (roll, pitch and yaw) or altitude\nA first-order, six-parameter, linear transformation is sufficient to rectify the imagery to a geographic frame of reference.\nThis type of transformation can model 6 kinds of distortions (Novak 1992; Buiten and Van Putten 1997):\n\nTranslation in x and y\nScale changes in x and y\nSkew\nRotation\n\nForward Mapping (input-to-output):\n\n\\[\nx = a_0 + a_1 x' + a_2 y'\n\\]\n\\[\ny = b_0 + b_1 x' + b_2 y'\n\\]\nThis forward mapping logic is useful when we rectify the location of discrete coordinates along a linear feature. However, when we are filling a rectified output grid with values from an unrectified input image, forward mapping logic is not very useful as the output location may not fall exactly on a x,y output map coordinate.\nThis can result in output matrix pixels with no output values (Wolberg 1990)\n\nInverse Mapping (output-to-input)\n\n\\[\nx' = a_0 + a_1 x + a_2 y\n\\]\n\\[\ny' = b_0 + b_1 x + b_2 y\n\\]\nThe rectified output matrix is filled systematically, with the equation using the six coefficient to determine where to get a value from the original input image. Here, nearest-neighbour resampling logic is used.\nA quadratic polynomial can also be used for transformations, but this is usually only used when there are serious geometric errors, usually in imagery obtained from suborbital aerial platforms.\n\\[\nx' = c_0 + c_1x + c_2y + c_3xy + c_4x^2 + c_5y^2\n\\]\n\\[\ny' = d_0 + d_1x + d_2y + d_3xy + d_4x^2 + d_5y^2\n\\]\nComputing the Root-Means-Squared-Error of the Inverse Mapping Function\nUsing RMSE allows us to determine how well the 6 coefficients derived from the least-squares regression of the initial GCPs account for the geometric distortion in the input image.\nThe user specifies a threshold of acceptable total RSME, and the GCP with the most individual error will be deleted, then recompute the 6 coefficients and RMSE for all points, until the RMSE is less than the threshold or there are too few GCPs remaining for a regression.\n\n\nIntensity Interpolation: Pixel brightness values should be determined. When a pixel in the rectified output image requires a value from the input pixel that does not fall neatly on a row-and-column coordinate, there must be a mechanism for determining the Brightness Value (BV) to be assigned to the output rectified pixel.\n\nSeveral methods of Brightness Value interpolation including nearest neighbour, bilinear interpolation and cubic convolution\nNearest neighbour is computationally efficient and does not alter BVs during resampling. It should be used when biophysical information is to be extracted from the dataset.\nBilinear interpolation assigns pixel values by interpolating BVs in 2 orthogonal directions, computing a new BV based on weighted distances to the nearest 4 pixel values. This method acts as a spatial moving filter that subdues extremes in BVs in the output image.\nCubic convolution assigns values similarly to bilinear interpolation, except that weighted values of 16 input pixels are used.\n\n\nImage-to-image registration\nThis is the translation and rotation alignment process by which 2 images of similar geometry and of same geographic area are positioned coincident to each other so that corresponding elements appear in the same place. This is used when it is not necessary to have each pixel assigned a unique x,y coordinate. A hybrid approach that uses both image-to-map rectification and image-to-image registration might be useful when detecting change between 2 or more dates of remotely sensed data."
  },
  {
    "objectID": "week3.html#summary-of-practical",
    "href": "week3.html#summary-of-practical",
    "title": "3  Week 3: Corrections",
    "section": "3.3 Summary of Practical",
    "text": "3.3 Summary of Practical\nThis practical covered basic correction concepts such as atmospheric correction, mosaicking and enhancements. For this practical, I decided to look at Landsat8 imagery of Serengeti National Park (SNP) in Tanzania. I will be summarising my takeaways from the mosaicking and ratio enhancement sections of the practical, as I found them to be particularly useful. I was also unable to perform the PCA section as it took too long for my computer.\n\n3.3.1 Mosaicking\nFor SNP, 3 tiles were needed to have a fuller view of the whole national park, so I downloaded 3 tiles that covered most of it. The first image shows the extent covered by the downloaded tiles, while the second shows the mosaicked output from R.\n\n\n\n\n\nFig. 1: Extent of tiles\n\n\n\n\n\n\n\n\n\nFig. 2: Mosaicked output\n\n\n\n\nThe mosaicked output in R was written to a GeoTiff file and then viewed in QGIS. It appears slightly off but I am unsure what went wrong in the process or this is an expected outcome.\n\n\n3.3.2 Ratio enhancements: NDVI\nThe Normalised Difference Vegetation Index is an application of ratioing, based on the fact that green vegetation absorbs the Red wavelength but reflects more in the NIR wavelength. This is illustrated as:\n\n\n\n\n\nFig. 3: Spectral traits of vegetation\n\n\n\n\nSource: PhysicsOpenLab\n\\[\nNDVI =  \\frac{NIR - Red}{NIR + Red}\n\\]\nApplying the NDVI formula to my dataset, I obtained first\n\n\n\n\n\nFig. 4: NDVI of Serengeti National Park\n\n\n\n\nWe can also focus on areas where NDVI is equal or greater than 0.1:\n\n\n\n\n\nFig. 5: NDVI of Serengeti National Park 2\n\n\n\n\nWe observe that the vegetation is not as healthy as we might expect, and this is because the images used were between 24/10/22 and 31/12/22 which coincides with the drier period.\nThis also coincides with the visualisations obtained when using the Normalised Difference Moisture Index (NDMI) and focusing on areas where NDMI is equal or greater than 0.1:\n\n\n\n\n\nFig. 6: NDMI of Serengeti National Park\n\n\n\n\n\n\n\n\n\nFig. 7: NDMI of Serengeti National Park2\n\n\n\n\nData fusion is the process of appending new raster data to existing datasets or creating new raster datasets with different bands, and data fusion can be done with newly-created texture measures and the original data. Fusion can be done in R using the stack() function.\nWhen merging datasets obtained from different remote sensors, all datasets should be accurately registered to one another and resampled to the same pixel size. One component-substitution method available is Principle Component Analysis (PCA). At this stage I would have done Principal Component Analysis to scale the raster datasets, but unfortunately I was unable to complete the PCA part of the practical. PCA allows comparison of data that is not easily comparable in its raw form. Performing PCA would transform the original data to produce uncorrelated principal component images (Pratt 2013). An advantage of PCA-based pan-sharpening is that the number of bands is not restricted (Klonus and Ehlers 2009)"
  },
  {
    "objectID": "week3.html#applications-of-ratio-enhancements",
    "href": "week3.html#applications-of-ratio-enhancements",
    "title": "3  Week 3: Corrections",
    "section": "3.4 Applications of Ratio Enhancements",
    "text": "3.4 Applications of Ratio Enhancements\nThe normalised difference vegetation index (NDVI) is widely used for vegetation studies, with the NASA Global Inventory, Monitoring and Modelling Studies (GIMMS) global coverage dataset (Tucker et al 2005) being the most widely used AVHRR (Advanced Very High Resolution Radiometer) dataset. They form a relatively robust basis for detecting long-term trends in NDVI in most of the world’s semi-arid, dry sub-humid and sub-humid areas (Fensholt and Proud 2012).\nNDVI values can be used to determine and analyse drought-prone areas, such as Faridatul and Ahmed’s (2020) work incorporating NDVI values into a modified vegetation condition index (mVCI) which enhances the detection of agricultural drought in the study area of Bangladesh; or can be used to analyse crop yields based on Pinto et al.’s (2017) work on canola yields in Brazil.\nFocusing on Serengeti National Park, I thought it would be useful to use NDVI on satellite imagery of SNP for potential applications of monitoring anthropogenic impacts on the Protected Area or impacts of climate change on the ecosystem. For example, Boone et al (2006) use rainfall and vegetation data (and NDVI) to model Serengeti wildebeest migratory patterns. However, Anderson et al (2010) also make the point that we should be cautious when using NDVI to study wildlife hotspots as NDVI can represent the effects of multiple, correlated processes (e.g. biomass, forage quality, cover for predators etc.) that influence the presence of hotspots (e.g. herbivore hotspots)."
  },
  {
    "objectID": "week3.html#reflections",
    "href": "week3.html#reflections",
    "title": "3  Week 3: Corrections",
    "section": "3.5 Reflections",
    "text": "3.5 Reflections\nAs Andy mentioned in the lectures, it is unlikely that we would have to perform geometric corrections given that most datasets are “Analysis Ready Data” (ARD), but it is useful to know in the event that we encounter data that requires geometric correction, or even just understanding how the data products we use have been treated from their raw form.\nMosaicking is a useful process given the limitations of some remote sensing products regarding geographical extents, and might come in handy in future research. Nonetheless, Andy also mentioned how this process may not be as important today as it is incorporated in the Google Earth Engine (GEE) workflow, so I am excited to learn in future weeks how this process is done in GEE. Mosaicking is also a bit of a throwback personally, back to 2017-18 for me when I learnt how to orthorectify and mosaic in ERDAS Imagine software (which I realised I have forgotten most of by now) and I am excited to learn how the process has evolved today when we start using GEE."
  },
  {
    "objectID": "week3.html#references",
    "href": "week3.html#references",
    "title": "3  Week 3: Corrections",
    "section": "3.6 References",
    "text": "3.6 References\nAnderson, T. M., J. G. C. Hopcraft, S. Eby, M. Ritchie, J. B. Grace, H. Olff (2010) ‘Landscape-scale analyses suggest both nutrient and antipredator advantages to Serengeti herbivore hotspots’, Ecology, 91(5), 1519-29.\nBoone, R. B., S. J. Thirgood, J. G. C. Hopcraft (2006) ‘Serengeti Wildebeest Migratory Patterns Modeled from Rainfall and New Vegetation Growth’, Ecology, 87(8), 1987-94.\nBuiten, H. J. and B. Van Putten (1997) ‘Quality Assessment of Remote Sensing Registration- Analysis and Testing of Control Point Residuals’, ISPRS Journal of Photogrammetry & Remote Sensing, 52, 57-73. Available at: https://doi.org/10.1016/S0924-2716(97)83001-8\nFaridatul, M. I. and B. Ahmed (2020) ‘Assessing Agricultural Vulnerability to Drought in a Heterogeneous Environment: A Remote Sensing-Based Approach’, Remote Sensing, 12(20), 3363.\nFensholt, R. and S. R. Proud (2012) ‘Evaluation of Earth Observation based global long term vegetation trends — Comparing GIMMS and MODIS global NDVI time series’, Remote Sensing of Environment, 119, 131-47.\nJensen, J.R. (2015) Introductory Digital Image Processing, 4th edn, Pearson Higher Education US (A Remote Sensing Perspective).\nKlonus, S. and M. Ehlers (2009) ‘Performance of Evaluation Methods in Image Fusion’, Proceedings of the 12th International Conference on Information Fusion, Seattle, July 6-9 2009, p. 8.\nNovak, K. (1992) ‘Rectification of Digital Imagery’, Photogrammeric Engineering & Remote Sensing, 58(3), 339-44.\nPinto, D. G., D. C. Fontana, G. A. Damalgo, E. Fochesatto, M. B. Vicari, C. Bremm, G. R. da Cunha, J. A. de Gouvea, A. Santi (2017) ‘Correlations between spectral and biophysical data obtained in canola canopy cultivated in the subtropical region of Brazil’, Pesquisa Agropecuária Brasileira, 52 (10), 825-32.\nPratt, W. K. (2013) Introduction to Digital Image Processing, Boca Raton: CRC Press, p. 736.\nTucker, C. J., J. E. Pinzon, M. E. Brown, D. A. Slayback, E. W. Pak, R. Mahoney (2005) ‘An extended AVHRR 8-km NDVI dataset compatible with MODIS and SPOT vegetation NDVI data’, International Journal of Remote Sensing, 26, 4485-98.\nWolberg, G. (1990) Digital Image Warping, NY: John Wiley- IEEE Computer Society, p. 340."
  }
]