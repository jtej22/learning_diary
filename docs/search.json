[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Josiah’s Remote Sensing Learning Diary",
    "section": "",
    "text": "Self-Introduction\nWelcome to my learning diary on remote sensing! I am currently a MSc Urban Spatial Science student at UCL Centre for Advanced Spatial Analytics (CASA). Prior to this, I graduated from UCL with a BSc in Geography with Economics. I am mainly interested in using spatial analysis techniques to urban problems from a policymaking perspective, which explains why I am at CASA now. After graduation, I will be working with Housing Development Board (HDB) in Singapore, the key agency responsible for public housing in the country. I have also interned with Singapore’s Ministry of Sustainability and Environment before, and am interested in urban environmental issues. Before my undergraduate studies, I also had a brief stint in the military where I had some exposure to pre-processing satellite imagery and digitizing maps. Through this module, I hope to learn necessary and relevant skills and techniques that can be applied to both urban housing and environmental contexts."
  },
  {
    "objectID": "week1.html#learning-objectives",
    "href": "week1.html#learning-objectives",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.1 Learning Objectives",
    "text": "1.1 Learning Objectives\nThe learning objectives of both the lecture and practical are:\n\nUnderstand the science behind remote sensors and how satellite imagery is obtained\nUnderstand how remotely sensed data work\nSource, load and articulate the differences between Landsat and Sentinel data\nUndertake basic raster image statistics and processing\nEvaluate the (dis)advantages of each type of software you have used\nPull out and statistically compare spectral signatures"
  },
  {
    "objectID": "week1.html#summary-of-key-concepts",
    "href": "week1.html#summary-of-key-concepts",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.2 Summary of Key Concepts",
    "text": "1.2 Summary of Key Concepts\n\n1.2.1 Overview of key content:\nThis week’s learning diary entry wll focus on the types of sensors and data resolutions available in remote sensing.\n\n\n1.2.2 Types of sensors\nThere are 2 main types of sensors, passive and active sensors. The key difference is that passive sensors (e.g. cameras, satellite sensors) usually detect reflected energy from the Sun while active sensors (e.g. LiDAR, radar, X-Ray) actively emit electromagnetic (EM) waves and detected the reflected waves.\nThis difference will be useful as the usefulness of the data from different types of sensors will be affected. Passive sensors which rely on reflected energy are thus dependent on the Sun, meaning that the time and day the image is captured will affect the imagery’s usefulness, as well as if there’s presence of cloud cover as clouds will be captured too. This may render the images less useful and users have to use images from another recorded day. Active sensors are more able to bypass clouds and this means that their recorded data is usually not affected by cloud cover and more useful. This also ties into the scientific concept of EM waves, as active sensors record data from a wider range of the EM spectrum compared to passive sensors, hence it can “see” through clouds and other atmospheric conditions.\n\n\n1.2.3 Data resolutions\nThe 4 types of resolutions are:\n\nSpatial: Size of the raster grid per pixel\nSpectral: Number of bands it records data in\nTemporal: Frequency of revisiting the site\nRadiometric: Differences in light or reflectance"
  },
  {
    "objectID": "week1.html#summary-of-practical-content",
    "href": "week1.html#summary-of-practical-content",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.3 Summary of Practical Content",
    "text": "1.3 Summary of Practical Content\nThe practical gave me the opportunity to explore the differences between Sentinel and Landsat data, as well as go through the practical process of searching for and downloading the relevant datasets. While I am slightly clearer on the general process, I am still perplexed by the vast options available such as choosing platforms, product types, and what is the best practice for choosing relevant imagery for different purposes.\nWhen exploring the Sentinel data it was helpful to see the various bands and that solidified my understanding of spectral bands practically.\n\n\n\n\n\nFig. 1: Bands available in Sentinel data\n\n\n\n\n\n1.3.1 Colour composites\nColour composites are a way of manipulating the way rasters are visualised (not actually modifying the raster data) so that we can focus on different aspects. The RGB image allows us to see the raster data in a way that is intuitive. There are other composites (band combinations) that are useful such as:\n\nFalse colour (Color infrared) composite: Emphasizes vegetation health, with denser vegetation appearing red while urban areas appear white\n\nThis is because vegetation absorbs red\n\nAtmospheric penetration composite: does not use visible bands so as to not be affected by atmospheric particles\n\nVegetation appears blue, urban area appears white, gray cyan or purple.\n\nShortwave infrared composite: Used to illustrate vegetation in different shades of green (differing densities) and brown areas represent built up or bare soil.\nMore information can be found on gisgeography\n\n\n\n1.3.2 Scatterplot analysis\nWe were exposed to a really cool method of using scatterplots to statistically analyse images, and created a plot of Band 8 (y-axis) against Band 4 (x-axis).\nFor this practical, my city of choice was Cape Town, South Africa, which was the city Andy used in the practical instructions. I chose this city as I wanted to focus on familiarising with the layout and tools in SNAP and R and not worry about differences in inputs from Andy’s example.\nThe scatterplot I obtained is as follows:\n\n\n\n\n\nFig. 2: Tasseled Cap using Cape Town imagery\n\n\n\n\nThis scatterplot can be interpreted as follows:\n\n\n\n\n\nFig. 3: Interpretation of Tasseled Caps\n\n\n\n\nSource: Remote Sensing 4113\n\n\n1.3.3 Resampling and Masking\nResampling and Masking are essential processes when dealing with raster data.\nMasking is essentially clipping like what we saw in CASA0005, and this can be done with vector data (ESRI Shapefile .shp) in SNAP.\nResampling is the change of spatial resolution (either increasing or decreasing) of the raster dataset. Resampling calculates new pixel values from the original pixel values in the original image.\nThere are various resampling techniques:\n\nNearest Neighbour Resampling\n\nTakes the cell centre from the input raster to determine the closes cell centre of the output\nFastest method because of its simplicity\nIdeal for categorical, nominal and ordinal data as it does not alter values\nE.g. useful for landcover classification raster grid\n\nBilinear Interpolation\n\nCalculates values of a grid based on 4 nearby grids\nAssigns the output cell value by taking a weighted average\nUseful when working with continuous datasets that do not have distinct boundaries\nE.g. useful for noise distance rasters\n\nCubic Convolution Interpolation\n\nSimilar to bilinear interpolation\nUses 16 nearest cells instead\nLong processing time\nUsually used for continuous surfaces where much noise exists\n\nMajority Resampling\n\nSimilar to nearest neighbour algorithm\nInstead uses the most common values in a filter window\n\n\n\n\n1.3.4 Spectral Signatures\nComparing Landsat and Sentinel products, we only focus on overlapping bands which are B2-4.\nIn R, we use the shapefiles for each landcover type to extract pixel values from the raster data. This is done using the R package terra. As with CASA0005, it is important to check the CRS of our data. We use terra’s extract function to extract values from our raster, and we repeat this for each landcover type for each image type (Landsat and Sentinel).\nUsing these values, we plot spectral profiles and density plots to observe differences between landcover types.\n\n\n\n\n\nFig. 4a: Sentinel Spectral Reflectance\n\n\n\n\n\n\n\n\n\nFig. 4b: Landsat Spectral Reflectance\n\n\n\n\nComparing the two outputs, we firstly see that the Landsat plot only has 3 land-cover types as there was no high-urban POI in the Landsat file (due to differences in areas covered). The number of bands plotted is the number of bands that are available in the product. Ideally, we want each landcover type to have a distinct signature at each band so that we can use the raster products for landuse classification.\nFor both plots, there isn’t much of a distinct spectral signature any of the landcover types, and there is a fair amount of overlap between the landcover types in each band. This means that the raster products used are not the most ideal for landcover classification and more image processing might be needed. It should also be noted that while the Landsat plot looks less differentiated, the mean values on the y-axis are of different scales from the y-axis values for the Sentinel plot."
  },
  {
    "objectID": "week1.html#applications-of-key-concepts-and-skills",
    "href": "week1.html#applications-of-key-concepts-and-skills",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.4 Applications of Key Concepts and Skills",
    "text": "1.4 Applications of Key Concepts and Skills\n\n1.4.1 Spectral Signatures\nAn interesting application of spectral signatures in academic studies is the analysis of the effects of low-backscattering areas of anthropogenic and natural origin on the azimuth autocorrelation function (AACF) using VV-polarised SAR measurements (Corcione et al. 2021). This is of great interest for the marine pollution community to better differentiate between natural low-backscattering or human pollution."
  },
  {
    "objectID": "week1.html#reflections",
    "href": "week1.html#reflections",
    "title": "1  Week 1: Introduction to Remote Sensing",
    "section": "1.5 Reflections",
    "text": "1.5 Reflections\n\n1.5.1 Reflections on data resolutions\nSpatial and temporal resolution are concepts that are fairly straightforward to me, as I used to be a mapper with the Singapore Armed Forces, where both types of resolutions were practical considerations when we were digitising areas of interest as it affected how clearly we could observe features and when choosing image files to use.\nSpectral resolution was of particular interest to me, as it is the key area that is involved in remote sensing analysis. Objects appear as a certain colour on satellite imagery because that is the wavelength that is reflected, and in the raster data from remote sensors, we can observe values for each wavelength across the EM spectrum. This allows us to create a spectral signature which helps us identify different features or land-covers. This concept is explored more practically later.\nRadiometric resolution is the ability of a sensor to detect and record differences in energy, and the higher radiometric resolution a sensor has, the more sensitive it is to differences on the ground. This means the image is of better quality.\n\n\n1.5.2 POIs\nJust a note on POIs, while the practical suggested various land-cover types such as bare earth, water grass, forest and urban, I interpreted these land-cover types according to my prior experience of landcover classification in Singapore. This meant I did not find any suitable POIs for the forest category as it was mostly bare earth, grass and farmland in the tile. Upon clarification with Andy, the main takeaway is that POIs depend on the area chosen and research objectives, and what types of landcover are present. It is up to the researcher to define the classifications.\nWe can also rely on landcovers classified by other researchers such as Dynamic World and reference their 9 land use and cover types (e.g. trees, grass, shrub & scrub and snow & ice)\n\n\n1.5.3 Spectral Signatures\nSpectral signatures will be key in my remote sensing journey moving forward. Regarding resources for spectral signatures that might be useful in the future, there is the USGS Spectral Library where we can reference the spectral reflectance of various materials for identification purposes. There is also the Awesome Spectral Indices list which keeps track of classical and novel spectral indices for different Remote Sensing applications.\n\n\n\n\nCorcione, Valeria, Andrea Buono, Ferdinando Nunziata, and Maurizio Migliaccio. 2021. “A Sensitivity Analysis on the Spectral Signatures of Low-Backscattering Sea Areas in Sentinel-1 SAR Images.” Remote Sensing 13 (6): 1183. https://doi.org/10.3390/rs13061183."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Week 3: Corrections",
    "section": "",
    "text": "Understand and apply types of corrections that can be applied to remotely sensed data\nUnderstand and apply methods of data joining and enhancement\nUnderstand how enhancements can be used to emphasize certain features or spectral traits"
  },
  {
    "objectID": "week3.html#summary-of-key-concepts",
    "href": "week3.html#summary-of-key-concepts",
    "title": "3  Week 3: Corrections",
    "section": "3.2 Summary of Key Concepts",
    "text": "3.2 Summary of Key Concepts\n\n3.2.1 Overview of content:\nIn this lecture, we mainly looked at types of corrections that could be applied to remotely sensed data:\n\nGeometric\n\nUse Ground Control Points (GCPs) to match points in the new image to a reference dataset.\nIdeally done with backward mapping (output to input) so that we can get a value in the original input image for every value in the gold standard (Jensen 2015, 247).\nAnd resample the final raster\n\nAtmospheric\n\nRelative (e.g. Dark Object Subtraction or Pseudo-Invariant Features)\nAbsolute; using atmospheric radiative transfer models, assuming atmospheric measurements are available (e.g. Py6S)\n\nOrthorectification/ Topographic Correction\n\nRemoving distortions such that the pixels viewed at nadir (straight down)\nRequires sensor geometry and DEM.\nCosine correction can be used (Jensen 2015)\n\nRadiometric\n\nUsing Digital Number to obtain spectral radiance\n\n\nWe also looked at how remotely sensed data can be mosaicked and enhanced. Mosaicking is the process of joining 2 or more images together, similar to merging in the sense of polygons.\nTypes of Enhancements and methods:\n\nContrast enhancement:\n\nMinimum-Maximum\nPercentage Linear and Standard Deviation\nPiecewise Linear Contrast Stretch\n\nBand Ratioing\nFiltering\nPrincipal Component Analysis (PCA)\n\n\n\n3.2.2 Geometric Corrections and Mosaicking (Jensen 2015)\nFor this week’s learning diary, I will be focusing on types of geometric corrections and the mosaicking process, based on Jensen’s textbook (2015).\nGround Control Points are locations on the road surface that can be easily and accurately identified on a map. Each GCP should have 2 distinct sets of coordinates, image and map coordinates.\nImage-to-map rectification\nThis is the process by which the geometry of an image is made planimetric, to remove distortion caused by topographic relief displacement.\nSteps:\n\nSpatial Interpolation: The geometric relationship between input pixel coordinates and reference map coordinates must be identified, to establish the nature of transformation to be applied to all other pixels.\n\nUnsystematic errors in the new image produced by changes in attitude (roll, pitch and yaw) or altitude\nA first-order, six-parameter, linear transformation is sufficient to rectify the imagery to a geographic frame of reference.\nThis type of transformation can model 6 kinds of distortions (Novak 1992; Buiten and Putten 1997)\n\nTranslation in x and y\nScale changes in x and y\nSkew\nRotation\n\nForward Mapping (input-to-output):\n\n\\[\nx = a_0 + a_1 x' + a_2 y'\n\\]\n\\[\ny = b_0 + b_1 x' + b_2 y'\n\\]\nThis forward mapping logic is useful when we rectify the location of discrete coordinates along a linear feature. However, when we are filling a rectified output grid with values from an unrectified input image, forward mapping logic is not very useful as the output location may not fall exactly on a x,y output map coordinate.\nThis can result in output matrix pixels with no output values (Wolberg 1990)\n\nInverse Mapping (output-to-input)\n\n\\[\nx' = a_0 + a_1 x + a_2 y\n\\]\n\\[\ny' = b_0 + b_1 x + b_2 y\n\\]\nThe rectified output matrix is filled systematically, with the equation using the six coefficient to determine where to get a value from the original input image. Here, nearest-neighbour resampling logic is used.\nA quadratic polynomial can also be used for transformations, but this is usually only used when there are serious geometric errors, usually in imagery obtained from suborbital aerial platforms.\n\\[\nx' = c_0 + c_1x + c_2y + c_3xy + c_4x^2 + c_5y^2\n\\]\n\\[\ny' = d_0 + d_1x + d_2y + d_3xy + d_4x^2 + d_5y^2\n\\]\nComputing the Root-Means-Squared-Error of the Inverse Mapping Function\nUsing RMSE allows us to determine how well the 6 coefficients derived from the least-squares regression of the initial GCPs account for the geometric distortion in the input image.\nThe user specifies a threshold of acceptable total RSME, and the GCP with the most individual error will be deleted, then recompute the 6 coefficients and RMSE for all points, until the RMSE is less than the threshold or there are too few GCPs remaining for a regression.\n\n\nIntensity Interpolation: Pixel brightness values should be determined. When a pixel in the rectified output image requires a value from the input pixel that does not fall neatly on a row-and-column coordinate, there must be a mechanism for determining the Brightness Value (BV) to be assigned to the output rectified pixel.\n\nSeveral methods of Brightness Value interpolation including nearest neighbour, bilinear interpolation and cubic convolution\nNearest neighbour is computationally efficient and does not alter BVs during resampling. It should be used when biophysical information is to be extracted from the dataset.\nBilinear interpolation assigns pixel values by interpolating BVs in 2 orthogonal directions, computing a new BV based on weighted distances to the nearest 4 pixel values. This method acts as a spatial moving filter that subdues extremes in BVs in the output image.\nCubic convolution assigns values similarly to bilinear interpolation, except that weighted values of 16 input pixels are used.\n\n\nImage-to-image registration\nThis is the translation and rotation alignment process by which 2 images of similar geometry and of same geographic area are positioned coincident to each other so that corresponding elements appear in the same place. This is used when it is not necessary to have each pixel assigned a unique x,y coordinate. A hybrid approach that uses both image-to-map rectification and image-to-image registration might be useful when detecting change between 2 or more dates of remotely sensed data."
  },
  {
    "objectID": "week3.html#summary-of-practical-content",
    "href": "week3.html#summary-of-practical-content",
    "title": "3  Week 3: Corrections",
    "section": "3.3 Summary of Practical Content",
    "text": "3.3 Summary of Practical Content\nThis practical covered basic correction concepts such as atmospheric correction, mosaicking and enhancements. For this practical, I decided to look at Landsat8 imagery of Serengeti National Park (SNP) in Tanzania. I will be summarising my takeaways from the mosaicking and ratio enhancement sections of the practical, as I found them to be particularly useful. I was also unable to perform the PCA section as it took too long for my computer.\n\n3.3.1 Mosaicking\nFor SNP, 3 tiles were needed to have a fuller view of the whole national park, so I downloaded 3 tiles that covered most of it. The first image shows the extent covered by the downloaded tiles, while the second shows the mosaicked output from R.\n\n\n\n\n\nFig. 1: Extent of tiles\n\n\n\n\n\n\n\n\n\nFig. 2: Mosaicked output\n\n\n\n\nThe mosaicked output in R was written to a GeoTiff file and then viewed in QGIS. It appears slightly off but I am unsure what went wrong in the process or this is an expected outcome.\n\n\n3.3.2 Ratio enhancements: NDVI\nThe Normalised Difference Vegetation Index is an application of ratioing, based on the fact that green vegetation absorbs the Red wavelength but reflects more in the NIR wavelength. This is illustrated as:\n\n\n\n\n\nFig. 3: Spectral traits of vegetation\n\n\n\n\nSource: PhysicsOpenLab\n\\[\nNDVI =  \\frac{NIR - Red}{NIR + Red}\n\\]\nApplying the NDVI formula to my dataset, I obtained first\n\n\n\n\n\nFig. 4: NDVI of Serengeti National Park\n\n\n\n\nWe can also focus on areas where NDVI is equal or greater than 0.1:\n\n\n\n\n\nFig. 5: NDVI of Serengeti National Park 2\n\n\n\n\nWe observe that the vegetation is not as healthy as we might expect, and this is because the images used were between 24/10/22 and 31/12/22 which coincides with the drier period.\nThis also coincides with the visualisations obtained when using the Normalised Difference Moisture Index (NDMI) and focusing on areas where NDMI is equal or greater than 0.1:\n\n\n\n\n\nFig. 6: NDMI of Serengeti National Park\n\n\n\n\n\n\n\n\n\nFig. 7: NDMI of Serengeti National Park2\n\n\n\n\nData fusion is the process of appending new raster data to existing datasets or creating new raster datasets with different bands, and data fusion can be done with newly-created texture measures and the original data. Fusion can be done in R using the stack() function.\nWhen merging datasets obtained from different remote sensors, all datasets should be accurately registered to one another and resampled to the same pixel size. One component-substitution method available is Principle Component Analysis (PCA). At this stage I would have done Principal Component Analysis to scale the raster datasets, but unfortunately I was unable to complete the PCA part of the practical. PCA allows comparison of data that is not easily comparable in its raw form. Performing PCA would transform the original data to produce uncorrelated principal component images (Pratt 2013). An advantage of PCA-based pan-sharpening is that the number of bands is not restricted (Klonus and Ehlers 2009)"
  },
  {
    "objectID": "week3.html#applications-of-ratio-enhancements",
    "href": "week3.html#applications-of-ratio-enhancements",
    "title": "3  Week 3: Corrections",
    "section": "3.4 Applications of Ratio Enhancements",
    "text": "3.4 Applications of Ratio Enhancements\nThe normalised difference vegetation index (NDVI) is widely used for vegetation studies, with the NASA Global Inventory, Monitoring and Modelling Studies (GIMMS) global coverage dataset (Tucker et al. 2005) being the most widely used AVHRR (Advanced Very High Resolution Radiometer) dataset. They form a relatively robust basis for detecting long-term trends in NDVI in most of the world’s semi-arid, dry sub-humid and sub-humid areas (Fensholt and Proud 2012).\nNDVI values can be used to determine and analyse drought-prone areas, such as Faridatul and Ahmed’s (2020) work incorporating NDVI values into a modified vegetation condition index (mVCI) which enhances the detection of agricultural drought in the study area of Bangladesh; or can be used to analyse crop yields based on Pinto et al.’s (2017) work on canola yields in Brazil.\nFocusing on Serengeti National Park, I thought it would be useful to use NDVI on satellite imagery of SNP for potential applications of monitoring anthropogenic impacts on the Protected Area or impacts of climate change on the ecosystem. For example, Boone et al (2006) use rainfall and vegetation data (and NDVI) to model Serengeti wildebeest migratory patterns. However, Anderson et al (anderson?) also make the point that we should be cautious when using NDVI to study wildlife hotspots as NDVI can represent the effects of multiple, correlated processes (e.g. biomass, forage quality, cover for predators etc.) that influence the presence of hotspots (e.g. herbivore hotspots)."
  },
  {
    "objectID": "week3.html#reflections",
    "href": "week3.html#reflections",
    "title": "3  Week 3: Corrections",
    "section": "3.5 Reflections",
    "text": "3.5 Reflections\nAs Andy mentioned in the lectures, it is unlikely that we would have to perform geometric corrections given that most datasets are “Analysis Ready Data” (ARD), but it is useful to know in the event that we encounter data that requires geometric correction, or even just understanding how the data products we use have been treated from their raw form.\nMosaicking is a useful process given the limitations of some remote sensing products regarding geographical extents, and might come in handy in future research. Nonetheless, Andy also mentioned how this process may not be as important today as it is incorporated in the Google Earth Engine (GEE) workflow, so I am excited to learn in future weeks how this process is done in GEE. Mosaicking is also a bit of a throwback personally, back to 2017-18 for me when I learnt how to orthorectify and mosaic in ERDAS Imagine software (which I realised I have forgotten most of by now) and I am excited to learn how the process has evolved today when we start using GEE.\n\n\n\n\nBoone, Randall B., Simon J. Thirgood, and J. Grant C. Hopcraft. 2006. “Serengeti Wildebeest Migratory Patterns Modeled from Rainfall and New Vegetation Growth.” Ecology 87 (8): 1987–94. https://www.jstor.org/stable/20069184.\n\n\nBuiten, H. J., and B. van Putten. 1997. “Quality Assessment of Remote Sensing Image Registration  Analysis and Testing of Control Point Residuals.” ISPRS Journal of Photogrammetry and Remote Sensing 52 (2): 57–73. https://doi.org/10.1016/S0924-2716(97)83001-8.\n\n\nFaridatul, Mst Ilme, and Bayes Ahmed. 2020. “Assessing Agricultural Vulnerability to Drought in a Heterogeneous Environment: A Remote Sensing-Based Approach.” Remote Sensing 12 (20): 3363. https://doi.org/10.3390/rs12203363.\n\n\nFensholt, Rasmus, and Simon R. Proud. 2012. “Evaluation of Earth Observation Based Global Long Term Vegetation Trends  Comparing GIMMS and MODIS Global NDVI Time Series.” Remote Sensing of Environment 119 (April): 131–47. https://doi.org/10.1016/j.rse.2011.12.015.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing: A Remote Sensing Perspective. Pearson Education, Incorporated.\n\n\nKlonus, Sascha, and Manfred Ehlers. 2009. “2009 12th International Conference on Information Fusion.” In, 1409–16.\n\n\nNovak, Kurt. 1992. “Rectification of Digital Imagery.” PHOTOGRAMMETRIC ENGINEERING.\n\n\nPinto, Daniele Gutterres, Denise Cybis Fontana, Genei Antonio Dalmago, Elizandro Fochesatto, Matheus Boni Vicari, Carolina Bremm, Gilberto Rocca da Cunha, Jorge Alberto de Gouvêa, and Anderson Santi. 2017. “Correlations Between Spectral and Biophysical Data Obtained in Canola Canopy Cultivated in the Subtropical Region of Brazil.” Pesquisa Agropecuária Brasileira 52 (10): 825–32. https://doi.org/10.1590/s0100-204x2017001000001.\n\n\nPratt, William. 2013. Introduction to Digital Image Processing. Boca Raton: CRC Press. https://learning.oreilly.com/library/view/introduction-to-digital/9781482216691/.\n\n\nTucker, Compton J., Jorge E. Pinzon, Molly E. Brown, Daniel A. Slayback, Edwin W. Pak, Robert Mahoney, Eric F. Vermote, and Nazmi El Saleous. 2005. “An Extended AVHRR 8-Km NDVI Dataset Compatible with MODIS and SPOT Vegetation NDVI Data.” International Journal of Remote Sensing 26 (20): 4485–98. https://doi.org/10.1080/01431160500168686.\n\n\nWolberg, George. 1990. Digital Image Warping | Wiley. New York: John Wiley- IEEE Computer Society. https://www.wiley.com/en-us/Digital+Image+Warping-p-9780818689444."
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  Week 4: Policy",
    "section": "",
    "text": "Singapore is a tropical city-state located in Southeast Asia, and is well-known for being a “Green City” for its extensive incorporation of greenery into its urban form. In light of climate change and the need to transit to more sustainable forms of development, the Singapore government launched the Singapore Green Plan 2030in 2021 to drive the national agenda on sustainable development. As a low-lying island state, climate change is an existential threat for Singapore and there is a need to ensure its resilience to climate threats. There are 5 key pillars to the Singapore Green Plan (SGP):\n\nCity in Nature\n\nKey Goal: Set aside 50% more land (200 ha) for nature parks, intensify nature in gardens and parks, and for every household to live within 10 minutes walk of a park\n\nEnergy Reset\n\nKey Goals: Quadruple solar energy deployment by 2025, including covering rooftops of state-subsidised housing blocks with solar panels, and reduce domestic greenhouse gas emissions by at least 3 million tonnes per year by 2030.\n\nSustainable Living\n\nKey Goals: Reduce waste sent to landfills by 30% and encourage walking and cycling as transport options.\n\nGreen Economy\n\nKey Goals: Promote Green Finance and carbon trading\n\nResilient Future\n\nKey Goals: Better understand and protect coastlines against rising sea levels, and limit the urban heat island effect.\n\n\nFor the policy goals of protecting coastlines and limiting urban heat effects, it is admirable that Singapore is looking to incorporate remotely sensed data into its workflow for achieving these goals. To better understand and model rising sea levels and their effects on Singapore, the Public Utilities Board (PUB) has collaborated with National University of Singapore (NUS) to use remotely-sensed data and geospatial models. As for efforts mitigating Urban Heat Island effect, the National Parks agency (NParks) has deployed an island-wide network of climate sensors that collect data on wind speeds, humidity and temperature. The collected data will then be used in the Singapore Variable Resolution (SINGV) model (which models future climatic scenarios) and the Integrated Environment Modeller (IEM) (which helps urban planners optimise building layouts).\nRemote sensing data can be further incorporated into the the Singapore Green Plan workflow, and I would propose using it to help in the achievement of the City in Nature goal. It should also be noted that the City in Nature goal is in line with Sustainable Development Goals (SDGs) 11 (Sustainable Cities and Communities), 13 (Climate Action) and 15 (Life on Land)."
  },
  {
    "objectID": "week4.html#application-of-remotely-sensed-data-to-the-city-in-nature-goal",
    "href": "week4.html#application-of-remotely-sensed-data-to-the-city-in-nature-goal",
    "title": "4  Week 4: Policy",
    "section": "4.2 Application of remotely sensed data to the City in Nature goal",
    "text": "4.2 Application of remotely sensed data to the City in Nature goal\nI would propose the use of remote sensing methods to measure and track the intensity of nature in gardens and parks.\nBefore I go into the details of how this can be done specifically in Singapore’s context, I will first do a literature review on current methodologies on urban vegetation.\nFor this, I refer to Neyns and Canters’ (2022) overview on current literature on urban vegetation in remote sensing. Scholars either define vegetation types based on functionality or taxonomic classes. Studies that analyse vegetation type by functionality tend to focus on the provision of ecosystem services., while classification by species in the urban environment tends to be more challenging due to noise.\nAs for the type of sensor data, it is noted that high spatial resolution (which is desirable to ensure that the vegetation is larger than a pixel) usually comes with a tradeoff on spectral resolution (which is better for mapping results). As for spectral bands, Li et al (2015)] found that the newly added red edge and NIR2 bands of Worldview 2 and 3 contribute more to the differentiation of tree species compared to the traditional four bands of Worldview 1 (red, green, blue, NIR). The mapping of individual trees becomes easier from a resolution of 3m or higher, and both spaceborne and airborne sensors can produce imagery at this resolution. Degerickx et al (2020) also found that structural variables derived from LiDAR data was more useful than hyperspectral variables. Using multi-temporal data is also useful to assess the influence of the time of data acquisition as well as in the classification process. However, given the relative stability of Singapore’s weather throughout the year, this may not be as essential.\nAs for feature definition, there are several types discussed such as spectral, textural, geometric, contextual and LIDAR-derived features. Spectral features use vegetation indices such as NDVI (which was covered in week 3), although NDVI in urban environments may lead to the possible false labelling of red clay roofs as vegetation (Zhang, Feng, and Jiang 2010). Geometric features describing the size, shape and edge complexity of objects can be useful in identifying broader functional vegetation types due to their widely different spatial properties (i.e. the space they occupy). Contextual features use neighbouring characteristics, and can be used for the mapping of functional vegetation types, such as Wen et al. (2017) differentiating between road-side, park and residential trees by considering the relation between trees in a predefined area.\nWang et al (2019) concluded that fusion of spectral imagery with Light Detection And Ranging (LiDAR) data substantially improves the identification of tree species in a urban setting. Authors also deal with shadows in various ways such as omitting elements affected by shadow, or by performing shadow correction, or by including shadowed areas as separate classes.\nReferring to Ren et al’s (2017) work, we see that using NDVI with Landsat TM data is also useful in rapdily estimating urban vegetation structural attributes such as leaf area index (LAI), crown closure (CC) and basal area (BA) at a spatiotemporal 30m resolution. NDVI applied to Sentinel-2 images, combined with plant height information (using Digital Object Height Models) is also another method of analysing he spatial distribution of well-equipped greenspace areas with high health and recreational potential as well as areas for improvement in poorly-equipped urban areas (Juergens and Meyer-Heß 2022).\n\n4.2.1 Proposal\nCircling back to how Singapore can use remote sensing methods to plan and monitor greenspaces and vegetation intensity, I would propose using Landsat or Sentinel imagery with NDVI, combined with 3D datasets to analyse greenspaces and plan where improvements in greenspaces should occur based on Juergens and Meyer-Heß’s (2022)methodology. Following which, I propose that remote sensing methods also be incorporated into a monitoring process, to measure the change in vegetation intensity and if planned improvements to urban vegetation are successful. Given that this measurement is not needed frequently (probably once a year), I would recommend that airborne sensors be used, so that data of high spatial and spectral resolution can be gathered, making the measurement of urban vegetation intensity more accurate. LiDAR data should also be included so that it can be combined with spectral imagery. This will allow Singapore to more easily quantify and measure the effectiveness of their efforts to intensify urban vegetation in its goal to become a City in Nature."
  },
  {
    "objectID": "week4.html#reflections",
    "href": "week4.html#reflections",
    "title": "4  Week 4: Policy",
    "section": "4.3 Reflections",
    "text": "4.3 Reflections\nThinking about policy applications was helpful as it pushed me to consider the specific data sources and methodologies that could be used to achieve particular goals, and this was helpful as we could think through specific details rather than just “know” that remotely sensed data could be applied in different many ways. Obviously, there are more ways we can think about the practical applications of remotely sensed data in policy, but I enjoyed this start. While I now roughly understand the steps that can be taken to apply remote sensing methodologies in a policy context, I think the next step is to understand how I can actually do it practically, which I look forward to learning more about in the rest of the module.\n\n\n\n\nDegerickx, Jeroen, Martin Hermy, and Ben Somers. 2020. “Mapping Functional Urban Green Types Using High Resolution Remote Sensing Data.” Sustainability 12 (5): 2144. https://doi.org/10.3390/su12052144.\n\n\nJuergens, Carsten, and M. Fabian Meyer-Heß. 2022. “Experimental Analysis of Geo-Spatial Data to Evaluate Urban Greenspace: A Case Study in Dortmund, Germany.” KN - Journal of Cartography and Geographic Information 72 (2): 153–71. https://doi.org/10.1007/s42489-022-00107-5.\n\n\nLi, Dan, Yinghai Ke, Huili Gong, and Xiaojuan Li. 2015. “Object-Based Urban Tree Species Classification Using Bi-Temporal WorldView-2 and WorldView-3 Images.” Remote Sensing 7 (12): 16917–37. https://doi.org/10.3390/rs71215861.\n\n\nNeyns, Robbe, and Frank Canters. 2022. “Mapping of Urban Vegetation with High-Resolution Remote Sensing: A Review.” Remote Sensing 14 (4): 1031. https://doi.org/10.3390/rs14041031.\n\n\nRen, Zhibin, Ruiliang Pu, Haifeng Zheng, Dan Zhang, and Xingyuan He. 2017. “Spatiotemporal Analyses of Urban Vegetation Structural Attributes Using Multitemporal Landsat TM Data and Field Measurements.” Annals of Forest Science 74 (3): 1–14. https://doi.org/10.1007/s13595-017-0654-x.\n\n\nWang, Kepu, Tiejun Wang, and Xuehua Liu. 2019. “A Review: Individual Tree Species Classification Using Integrated Airborne LiDAR and Optical Imagery with a Focus on the Urban Environment.” Forests 10 (1): 1. https://doi.org/10.3390/f10010001.\n\n\nWen, Dawei, Xin Huang, Hui Liu, Wenzhi Liao, and Liangpei Zhang. 2017. “Semantic Classification of Urban Trees Using Very High Resolution Satellite Imagery.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 10 (4): 1413–24. https://doi.org/10.1109/JSTARS.2016.2645798.\n\n\nZhang, Xiuying, Xuezhi Feng, and Hong Jiang. 2010. “Object-Oriented Method for Urban Vegetation Mapping Using IKONOS Imagery.” International Journal of Remote Sensing 31 (1): 177–96. https://doi.org/10.1080/01431160902882603."
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "5  Week 5: Google Earth Engine (GEE)",
    "section": "",
    "text": "Understand how GEE works\nFamiliarise self with using GEE and its functionalities."
  },
  {
    "objectID": "week5.html#summary-of-key-content",
    "href": "week5.html#summary-of-key-content",
    "title": "5  Week 5: Google Earth Engine (GEE)",
    "section": "5.2 Summary of Key Content",
    "text": "5.2 Summary of Key Content\n\n5.2.1 Overview of content:\nThis week, we learnt more about Google Earth Engine (GEE), how it works with its Client and Server sides, and practicalities when using GEE such as scale/ resolution and projections.\n\n\n5.2.2 Background of Google Earth Engine\nGEE is a geospatial processing service that allows geospatial analysis at scale (volume-wise). It takes code that users write and applies it to data on their servers. GEE has unique names for the types of data we use, “image” for what we know as raster data and “feature” for what we know as vectors. There is also ImageCollection and FeatureCollections, which are equivalents of raster stacks and (possibly?) geodatabases. GEE also uses Javascript, which will be interesting as I have no prior exposure to Javascript.\n\n\n5.2.3 Concept of Client vs Server side\nWe can upload our own data on GEE, and that is on client side. But the other GEE data is on server side. We refer to these Earth Engine Objects using “ee” in front of it, and they are not available locally.\nThis implies that we shouldn’t loop on the server. Instead we create a function, and then apply it to what we want on the server. However, there are functions available on the server side too, and they are referred to with the “ee” in front too. Mapping is useful to be more computationally efficient when using GEE\n\n\n5.2.4 Scale/ resolution\nImage scale in GEE refers to pixel resolution. When analysing in GEE, GEE aggregates the image to fit a 256x256 grid. We have to set the scale parameter we need otherwise GEE will resample using nearest neighbour. GEE is aggregating the values based on our analysis extent. We can Input the minimum and maximum for bands to control how the image is visualised as well.\n\n\n5.2.5 Projections\nGEE uses EPSG 3857 as the default projection, and we do not need to worry about it until the end when we are exporting."
  },
  {
    "objectID": "week5.html#summary-of-practical-content-gee-in-action",
    "href": "week5.html#summary-of-practical-content-gee-in-action",
    "title": "5  Week 5: Google Earth Engine (GEE)",
    "section": "5.3 Summary of Practical Content: GEE in Action",
    "text": "5.3 Summary of Practical Content: GEE in Action\nThis week’s practical covers skills that we have covered before, but in GEE such as optimising the imagery used for analysis, mosaicking and clipping images, as well as texturing, PCA and indices. For this practical, I will be using New Delhi, which is the city Andy used in the practical, as I view this practical as more of a way to familiarise myself with GEE and future GEE practicals will be attempted with other cities.\n\n5.3.1 GEE Data\nOne thing that stood out to me was the wide variety of datasets available in Google Earth Engine’s Data Catalog. There were datasets available for Climate and Weather data (Surface Temperatures, Climate models, Atmospheric Data, Weather), Imagery (Landsat, Sentinel), MODIS and High-Resolution Imagery) as well as Geophysical data (DEMs, Land Cover maps, Cropland and other datasets such as night-time imagery). This wide variety makes GEE very useful for multiple types of methodologies and analysis, and I would be interested in exploring all the other datasets if time permits.\n\n\n5.3.2 Scaling factors\nScaling factors from Landsat surface reflectance product is something we have not really encountered before, and it is helpful to know this for future processing of Landsat imagery. However, I have not been able to find a good explanation online on the need to scale the imagery. After using scaling the imagery, I obtained a similar image to Andy’s.\n\n\n\n\n\nFig. 1: True Colour\n\n\n\n\nAfter scaling, mosaicking (including obtaining the mean of overlapping pixels) and clipping was done to obtain a smoother image below that fit New Delhi’s boundaries.\n\n\n\n\n\nFig. 2: Mosaicked and Clipped\n\n\n\n\n\n\n5.3.3 Texturing\nSatellite image texture quantifies spectral and spatial variations in pixel values of an image (Farwell et al. 2021), therefore conveying information about spectral and spatial heterogeneity of image features (Haralick, Shanmugam, and Dinstein 1973). The specific statistical method we apply here is the gray-level co-occurrence matrix (GLCM) which is a tabulation of how often different combinations of pixel brightness values (gray levels) occur in an image (Hall-Beyer 2017). It characterises the texture of an image by calculating how often pairs of pixels with specific values and in a specified spatial relationship occur in an image, thus creating a GLCM, and then statistical measures are extracted from this matrix. Texture measures then give us concepts like “contrast”, “dissimilarity” and “entropy”.\nWe compute GLCM texture for our area of interest and obtain the following output:\n\n\n\n\n\nFig. 3: GLCM Texture of New Delhi\n\n\n\n\nWe then zoom in to a specific area to observe what the computed GLCM texture tells us:\n\n\n\n\n\n\n\n(a) True Colour\n\n\n\n\n\n\n\n(b) GLCM\n\n\n\n\nFigure 5.1: Comparison of True Colour Image and GLCM Texture to understand what it shows\n\n\nWe see that the purple spots in the GLCM texture appear to be buildings that are especially reflective in the True Colour image.\n\n\n5.3.4 PCA\nWhen performing PCA, we are transforming the multi-spectral data we have into a uncorrelated and smaller dataset, while keeping most of the original information. The first component should also capture most of the variance within the dataset. This was the PCA output obtained:\n\n\n\n\n\nFig. 4: PCA\n\n\n\n\n\n\n\n\n\n\n\n(a) True Colour\n\n\n\n\n\n\n\n(b) PCA\n\n\n\n\nFigure 5.2: Comparison of True Colour Image and PCA output to understand what it shows"
  },
  {
    "objectID": "week5.html#applications-of-key-concepts",
    "href": "week5.html#applications-of-key-concepts",
    "title": "5  Week 5: Google Earth Engine (GEE)",
    "section": "5.4 Applications of key concepts",
    "text": "5.4 Applications of key concepts\nGLCM and PCA can be used together in remote sensing research. In forestry mapping, such as mapping bamboo forests, textural features such as homogeneity, contrast, entropy and variance of GLCM can be used as classification features(Qi et al. 2022). In this study, textural features were derived from the first component image from a PCA. In a object-oriented LULC classification study (Tassi and Vizzari 2020), they used GLCM to first calculate textural indices from satellite imagery, and then doing a PCA of the most relevant GLCM metrics to synthesize the textural information. Based on what we observe from current literature, GLCM is usually used to extract textural information from the raster datasets, and PCA done to reduce the number of bands and extract key components, making further steps such as classification easier(Shafizadeh-Moghadam et al. 2021)."
  },
  {
    "objectID": "week5.html#reflections",
    "href": "week5.html#reflections",
    "title": "5  Week 5: Google Earth Engine (GEE)",
    "section": "5.5 Reflections",
    "text": "5.5 Reflections\nThis week’s content has familiarised myself with GEE, and hopefully with further use of it, I will become better at understanding the breadth of functions it has in remote sensing analysis. I will also become more aware of limitations of GEE, such as how it might not be the best for doing in-depth geographic analysis with raster data as it has limited analytical functions compared to R for example. We saw how to do classic remote sensing processing steps such as mosaicking and clipping in GEE.\nThe practical on texturing was useful in helping me understand how raster data works and how it can be used practically for landcover classification. This knowledge seems to be useful for what we’ll be covering in future weeks.\n\n\n\n\nFarwell, Laura S., David Gudex-Cross, Ilianna E. Anise, Michael J. Bosch, Ashley M. Olah, Volker C. Radeloff, Elena Razenkova, et al. 2021. “Satellite Image Texture Captures Vegetation Heterogeneity and Explains Patterns of Bird Richness.” Remote Sensing of Environment 253 (February): 112175. https://doi.org/10.1016/j.rse.2020.112175.\n\n\nHall-Beyer, Mryka. 2017. “GLCM Texture: A Tutorial v. 3.0 March 2017.”\n\n\nHaralick, Robert M., K. Shanmugam, and Its’Hak Dinstein. 1973. “Textural Features for Image Classification.” IEEE Transactions on Systems, Man, and Cybernetics SMC-3 (6): 610–21. https://doi.org/10.1109/TSMC.1973.4309314.\n\n\nQi, Shuhua, Bin Song, Chong Liu, Peng Gong, Jin Luo, Meinan Zhang, and Tianwei Xiong. 2022. “Bamboo Forest Mapping in China Using the Dense Landsat 8 Image Archive and Google Earth Engine.” Remote Sensing 14 (3): 762. https://doi.org/10.3390/rs14030762.\n\n\nShafizadeh-Moghadam, Hossein, Morteza Khazaei, Seyed Kazem Alavipanah, and Qihao Weng. 2021. “Google Earth Engine for Large-Scale Land Use and Land Cover Mapping: An Object-Based Classification Approach Using Spectral, Textural and Topographical Factors.” GIScience & Remote Sensing 58 (6): 914–28. https://doi.org/10.1080/15481603.2021.1947623.\n\n\nTassi, Andrea, and Marco Vizzari. 2020. “Object-Oriented LULC Classification in Google Earth Engine Combining SNIC, GLCM, and Machine Learning Algorithms.” Remote Sensing 12 (22): 3776. https://doi.org/10.3390/rs12223776."
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "6  Week 6: Classification 1",
    "section": "",
    "text": "Use vector and EO Data\nUnderstand Landuse Landcover Classification Methods\nUnderstand Train-test splits"
  },
  {
    "objectID": "week6.html#summary-of-key-concepts",
    "href": "week6.html#summary-of-key-concepts",
    "title": "6  Week 6: Classification 1",
    "section": "6.2 Summary of Key Concepts",
    "text": "6.2 Summary of Key Concepts\n\n6.2.1 Overview of content:\nIn this week’s lecture we looked at examples of land-use/ landcover (LULC) that we had encountered before throughout this module, before diving into classification methodologies.\nApplications of LULC classifications include urban expansion (MacLachlan et al. 2017) , air pollution (Fuladlu and Altan 2021), urban green spaces (Shahtahmassebi et al. 2021), forest monitoring (Hansen et al. 2013) and forest fires (Chuvieco and Congalton 1989). We then looked at classification methods which this learning diary entry will focus on.\n\n\n6.2.2 Classification Methodologies: Classification and Regression Trees (CART)\nClassification Trees: Classifying data into 2 or more discrete categories\nWhat variable do we start a classification tree with (the root of the tree)? We use the Gini Impurity to determine that. The variable with the lowest impurity goes at the root, and use the Gini Impurity at each branch to split the nodes/ leaves.\n\\[ Gini Impurity = 1 - (probability-of-yes)^2 - (probability-of-no)^2 \\]\nTake weighted average for the variable too, and lowest impurity wins.\nWe use classification trees for landcover classification\nRegression Trees: Predicting continuous dependent variables.\nWe use Sum of Squared Residuals to divide the data into sections.\nLowest SSR wins and is used as the root of the tree. Repeat process of finding SSR for each segment to continue the classification. Each leaf is a numeric value. We can do this with many predictor variables\nOverfitting occurs when we have a leaf with just one value (pure output). We want a good balance between bias and variance.\nTo prevent overfitting, we limit how trees grow by setting a minimum number of observations in a leaf (from the top); (e.g. 20 pixels so that there is some degree of generalisation)\nor we can do weakest link pruning (with tree score). WLP prunes from the bottom. Tree score = SSR + tree penalty (alpha) * T (number of leaves).\nWeakest Link Pruning process: Run a full tree with all data. Look at leaves’ SSR. Remove a leaf, and see if SSR improves. To do that we use Tree Score. Key thing is tree penalty. We compute tree penalty by using a full size regression tree with all the data. Start with a value of 0 (which gives lowest tree score). Save values of alpha that gives a lower tree score than when a=0. Increase value of alpha until we get a lower tree score than the original.\nTrain-test split (70-30). Use training data and use alpha values from before. Calculate SSR. Calculate alpha by letting it run.\nUsing test data, and tree, calculate sum of squared residuals (for all values of alpha) –> use the value of alpha which gives lowest tree score.\nCross-validate by changing the data in test-train sets. Do it 10 times (ten-fold cross validation). Use the value of alpha that gives lowest SSR across all cross-validation\nThis process makes the tree more generalisable, and is basically identifying the weakest leaves and removing them from the tree\nDifferent classifiers give different results, but we can’t really say one classifier is better than another\n\n\n6.2.3 Comparison of classifiers\n\nDecision Tree deals with collinearity.\nIn a Decision Tree, each division could be based on different bands from input. While in SVM, its a multi-dimensional array plot and fitting planes.\nRandomForest and Decision Trees have low computation cost and easy to visualise\nSupport Vector Machine does not deal with collinearity because we’re fitting a plane ((using x,y values) rather than dividing data"
  },
  {
    "objectID": "week6.html#summary-of-practical-content",
    "href": "week6.html#summary-of-practical-content",
    "title": "6  Week 6: Classification 1",
    "section": "6.3 Summary of Practical Content",
    "text": "6.3 Summary of Practical Content\n\n6.3.1 Overview:\nLoad admin boundary vector data\nLoad raster data by specifying image collection, date range, intersecting region of interest, and cloud percentage threshold.\nWe can either use median value of all pixels through the image stack (lazy way that neglects temporal variation in data) or take deciles (Hansen’s way) –> pattern vector becomes much bigger to draw upon the seasonality of the data.\nAdd polygons for landcovers we are interested in classifying or use a pixel approach to get more accurate results\nInsert a train-test split here to test the model\nSet the bands we are using for classification and classification property.\nTrain classifier, classify image, and plot output.\nNote the trap of spatial autocorrelation when selecting POIs and pixels to train classifiers\n\n\n6.3.2 Practical Output\nFor this practical I used Ulanbaatar, the capital of Mongolia. However, due to the level 2 Administrative Boundaries and to obtain different landcovers, the output covers the southern outskirts of Ulanbaatar.\nI first obtained an image stack that contained median values of all pixels over the date range (rather than percentiles).\n\n\n\n\n\n\nTrue Colour of median values for Ulanbaatar\n\n\n\n\n\n\n\nGoogle Maps’ classification of features\n\n\n\n\n\n\nUlanbaatar\n\n\n\nWe see that the river appears more like a line in the satellite imagery while it is drawn as a polygon in Google Maps. We also note the demarcation of “forest” and “mountainous” areas on Google Maps and how it appears on the satellite imagery.\n\n\n\n\n\n\nClassified Landcover\n\n\n\n\n\n\n\nClassified Pixel Landcover\n\n\n\n\n\n\nComparing classification methods\n\n\n\nThe first method trained the model using the polygons extracted, while the polygons I drew were not very precise, hence you can see polygons in the first image such as in the river and urban areas. The second method selected some pixels from each landcover class I drew, generated a train-test split, and extracted values to train the model. This pixel approach resulted in a smoother classification compared to the first one.\n\n\n\n\n\n\nLarge Classified Pixel Landcover\n\n\n\n\n\n\n\nLarge Landcover raw version\n\n\n\n\n\n\nObserving accuracy\n\n\n\nWe see that for the large administrative area with multiple landcovers, the pixel method is fairly accurate, and the overall accuracy was 78.84%."
  },
  {
    "objectID": "week6.html#application-of-key-concepts-and-skills",
    "href": "week6.html#application-of-key-concepts-and-skills",
    "title": "6  Week 6: Classification 1",
    "section": "6.4 Application of Key Concepts and Skills",
    "text": "6.4 Application of Key Concepts and Skills\nWith the accessibility of Google Earth Engine, there is an increasing number of landcover classification studies being done, some of which I presented in last week’s learning diary entry. For this learning diary, I will focus on various types of LULC classification methods and how they differ.\nPhiri and Morgenroth’s (2017) review of LULC classification methods and how they have evolved over time is especially insightful and summarises these developments well. They mention how most classification methods (e.g. ) were developed in the 1970s and 80s, but advancements in classifiers and algorithms have come after the 2000s.\n\nTable 1: History of LULC\n\n\n\n\n\n\nTime period\nDevelopments\n\n\n\n\n1970s\n\nEarly Pattern Recognition\nSupervised and unspervised pixel-based classification methods (e.g using maximum likelihood, K-means and Iterative Self-Organising Data Analysis Technique (ISODAT) classifiers)\n\n\n\n1980s\n\nSub-pixel based classification (e.g. Fuzzy approach and Spectral Mixture Analysis)\nContext-based analysis\nKnowledge-based analysis\nMachine Learning-based analysis\nImage segmentation\n\n\n\n1990s\n\nObject-Based Image Analysis (OBIA)\nData fusion of Landsat imagery with other sources\n\nAdvanced Very High-Resolution Radiometer (AVHRR)\nModerate-Resolution Imaging Spectroradiometer (MODIS)\nAnd more recently radar, LiDAR and SAR data\n\nOBIA tends to result in greater accuracy than pixel-based classifications due to OBIA’s segmentation algorithms and the ability to use spectral, textural and neighbourhood information in classification (Huth et al. 2012)\n\n\n\n2000s\n\nHybrid methods\nComparison of advanced algorithms\n\n\n\n2010s\n\nMore applications of OBIA\nAdvanced Classifiers\n\n\n\n\nThey (2017) concluded that OBIA classification seems to be the most common method and has major advantages, but its limitations include challenges in selecting the optimal segmentation scale, which can generate errors due to over- or under-segmentation, and misclassification of small landcover types due to the low/medium spatial resolution of Landsat images. There is not one best classification method for Landsat images, but researchers have to weigh strengths and limitations of each methods for their research purposes, and consider factors such as pre-processing quality and type of Landsat images being used. Some sources of errors in pre-processing include orthorectification and radiometric correction, which brings us back to what we learnt in week 3 about corrections, and we have to be conscious about such sources of errors and not assume all images are perfectly corrected."
  },
  {
    "objectID": "week6.html#reflections",
    "href": "week6.html#reflections",
    "title": "6  Week 6: Classification 1",
    "section": "6.5 Reflections",
    "text": "6.5 Reflections\nThis week, we dived into landuse landcover classification which is a big part of remote sensing research, learning more about the types of classifiers that can be used to achieve these objectives. I would be interested in experimenting with other locations and other classifiers to reproduce this week’s practical output, and see how classifier parameters can be tuned.\nThe article covered in the Application section was also particularly helpful in understanding how landcover classification in remote sensing has evolved over time. It is also a reminder of how as remote sensing researchers, we should remain curious and updated with new developments in methodologies in the remote sensing field, as it is constantly evolving and growing.\n\n\n\n\nChuvieco, Emilio, and Russell G. Congalton. 1989. “Application of Remote Sensing and Geographic Information Systems to Forest Fire Hazard Mapping.” Remote Sensing of Environment 29 (2): 147–59. https://doi.org/10.1016/0034-4257(89)90023-0.\n\n\nFuladlu, Kamyar, and Haşim Altan. 2021. “Examining Land Surface Temperature and Relations with the Major Air Pollutants: A Remote Sensing Research in Case of Tehran.” Urban Climate 39 (September): 100958. https://doi.org/10.1016/j.uclim.2021.100958.\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A. Tyukavina, D. Thau, et al. 2013. “High-Resolution Global Maps of 21st-Century Forest Cover Change.” Science 342 (6160): 850–53. https://doi.org/10.1126/science.1244693.\n\n\nHuth, Juliane, Claudia Kuenzer, Thilo Wehrmann, Steffen Gebhardt, Vo Quoc Tuan, and Stefan Dech. 2012. “Land Cover and Land Use Classification with TWOPAC: Towards Automated Processing for Pixel- and Object-Based Image Classification.” Remote Sensing 4 (9): 2530–53. https://doi.org/10.3390/rs4092530.\n\n\nMacLachlan, Andrew, Eloise Biggs, Gareth Roberts, and Bryan Boruff. 2017. “Urban Growth Dynamics in Perth, Western Australia: Using Applied Remote Sensing for Sustainable Future Planning.” Land 6 (1): 9. https://doi.org/10.3390/land6010009.\n\n\nPhiri, Darius, and Justin Morgenroth. 2017. “Developments in Landsat Land Cover Classification Methods: A Review.” Remote Sensing 9 (9): 967. https://doi.org/10.3390/rs9090967.\n\n\nShahtahmassebi, Amir Reza, Chenlu Li, Yifan Fan, Yani Wu, Yue lin, Muye Gan, Ke Wang, Arunima Malik, and George Alan Blackburn. 2021. “Remote Sensing of Urban Green Spaces: A Review.” Urban Forestry & Urban Greening 57 (January): 126946. https://doi.org/10.1016/j.ufug.2020.126946."
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "7  Week 7: Classification 2",
    "section": "",
    "text": "Understand Advanced Classification Methods (sub-pixel and super pixel)\nLearn how to assess accuracy (and account for spatial dependence)"
  },
  {
    "objectID": "week7.html#summary-of-key-concepts",
    "href": "week7.html#summary-of-key-concepts",
    "title": "7  Week 7: Classification 2",
    "section": "7.2 Summary of Key Concepts",
    "text": "7.2 Summary of Key Concepts\nThis week’s lecture covered more classification methods and how to assess accuracy of classifers, as well as the importance of accounting for spatial dependence in classifiers. This learning diary will focus on the advanced classification methods covered, while briefly summarising the other content in point-form.\n\n7.2.1 Landcover classification methods\n\n7.2.1.1 Object-based image analysis (OBIA)\n\nSuperpixels: consider shapes (rather than cells) based on the homogeneity or heterogeneity of cells\nSimple Linear Iterative Clustering (SLIC) Algorithm is the most common method for superpixel generation\nParameters: distance (closeness to centre of pixel) and homogeneity of colours\nProcess:\n\nRequires several iterations for tuning and improving accuracy\nValues can change and borders can move.\n\n\n\n\n7.2.1.2 Sub-pixel analysis/ sub-pixel classification/ spectral mixture analysis/ linear spectral unmixing\n\nThis method estimates the proportion/ fractions of landcover that make up a pixel\nThis process is dependent on a few endmembers that are spectrally pure that can come from:\n\nSpectral library\nFrom image\nlabwork\nSub pixel analysis matrices: GEE makes it unconstrained by default, but constrain by setting sum to 1\n\n\n\nScatterplot of two-dimensional spectral data illustrating the physical interpretation of a mixture model based on endmembers\n\n\nSource: (Plaza et al. 2002)\n\nMakes a map of fractions\nSome considerations for this approach include:\n\nNumber of endmembers:\n\nThis could be simplified using the Vegetation–Impervious Surface- Soil model\n\n\n\nVIS model of Ridd (1995)\n\n\nSource: (Phinn et al. 2002)\nOr use Multiple Endmember Spectral Mixture Analysis (MESMA) (Fernández-García et al. 2021)\n\n\n\n\n\n\n7.2.2 Accuracy\nIn remote sensing, there are 3 main types of accuracy we focus on (Barsi et al. 2018)\n\nProducer accuracy (PA)\n\n\\[\nTP/ (TP + FN)\n\\]\n\nUser Accuracy (UA)\n\n\\[\nTP/ (TP + FP)\n\\]\n\nOverall Accuracy (OA)\n\n\\[\n(TP + TN) / (TP+FP+FN+TN)\n\\]\n\n\nThese are represented in a binary confusion matrix illustrating True Postive, True Negative (model is correct) and False Positive, False Negative (model is incorrect).\n\n\n7.2.3 Beyond remote sensing and into machine learning\n\nCombine into F1 score (Both PA and UA)\nF1 doesnt consider true negatives\nbut this depends on threshold\nReceiver Operating Characteristic Curve\n\nCalculate area under curve\n\nCross-validation\nSpatial auto-correlation: ideally use spatial cross-validation\n\n\n\n7.2.4 Spatial Cross-Validation\n\nSpatially partition the folded data\nDistance threshold (GEE)\nDisjoint (no common boundary) using k-means clustering\nSupport Vector Machine\n\nRather than using each fold to figure out C and gamma (overfits), take random sample from fold then get C and gamma (Lovelace, Nowosad, and Muenchow 2019).\nNot available in GEE yet but available in R\nGEE specific to satellite imagery, hard to do vector analysis and stuff"
  },
  {
    "objectID": "week7.html#summary-of-practical-content",
    "href": "week7.html#summary-of-practical-content",
    "title": "7  Week 7: Classification 2",
    "section": "7.3 Summary of Practical Content",
    "text": "7.3 Summary of Practical Content\nFor this week’s practical, we looked at using sub-pixels and super-pixels for classification. For super-pixels, the main outline was to take a grid of points and get the pixels, then reduce the pixels to fewer objects and finally classify the objects.\n\nFirst we cluster the pixels:\n\nK-means clustering\n\nee.Algorithms.Image.Segmentation.KMeans()\n\nor Simple Non-Iterative Clustering (SNIC)\n\nClusters pixels using normalised spatial and colour distances\nMake a seed grid first: ee.Algorithms.Image.Segmenttion.seedGrid()\nTo run SNIC: ee.Algorithms.Image.Segmentation.SNIC()\n\n\nExtract more information (e.g. NDVI) then create an image\n\nee.Image.cat()\n\nThen use a CART classifier for landcover classification\n\nee.Classifier.smileCart().train()\n\n\nFor this practical, I used Ahmedabad, India, which is also the city me and my group used for our group presentation.\n\n\n\n\n\n\nTrue Colour for Ahmedabad\n\n\n\n\n\n\n\n\n\nSub-pixel approach\n\n\n\n\n\n\n\n\n\nSuper-pixel approach\n\n\n\n\n\n\nLandcover Classification for Ahmedabad\n\n\n\nMy practical output gave very interesting results. My inputs were urban, grass, bare earth and forest areas, and there are only 3 typologies for the output. The pink areas are urban, grey bare earth and green seems to be a mix of forest and grass areas. Perhaps my input pixels were not distinct enough and human error resulted in this. For the super-pixel approach, it also seems to have not classified the river (black lines which are actually slivers when zoomed in, while the sub-pixel approach classified the river as grass/forest. If I were to repeat this, I would use endmembers from a spectral library rather than my own extracts. The superpixel output is more aesthetic compared to the sub-pixel at first glance too."
  },
  {
    "objectID": "week7.html#application-of-key-concepts-and-skills",
    "href": "week7.html#application-of-key-concepts-and-skills",
    "title": "7  Week 7: Classification 2",
    "section": "7.4 Application of Key Concepts and Skills",
    "text": "7.4 Application of Key Concepts and Skills\nHowever, one challenge for landcover classification is that of urban areas. Identifying and delineating urban areas is still a challenge because of the difficulty of disentangling surface reflectance of pixels due to the varied types of surface materials and structures in urban areas (Herold, Gardner, and Roberts 2003; Varshney and Rajesh 2014; MacLachlan et al. 2017). Spatial resolution is thus an important factor for accurate monitoring of LULC change.\nAccurate estimation of urban areas is also important as it is also used in other applications such as climate models or investigating urban heat island effects. What I found interesting in Andy’s article (2017) is how remote sensing methods are still developing and improving. In his article, he compares the use of Support Vector Machine (SVM) spectral unmixing and the novel sub and hard pixel Import Vector Machine (IVM) classifier. The IVM approach assess whether new samples (import vectors) can be removed in each forward step to provide a smoother decision boundary, and generates 2 outputs: a subpixel dataset that gives the probability of a pixel containing a given landcover type and a ‘hardened’ classified dataset. Andy argues that classified subpixel data alongside high spatial resolution imagery can refine estimates of urban areas, facilitating improved decision-making that maximises financial resources. Nonetheless, it is also important to be conscious of how spatial structure and composition of urban and suburban areas differ regionally, nationally and globally (MacLachlan et al. 2017).\nAs remote sensing researchers, we should remain up to date with the latest classifier methods and understand how they work so as to use satellite imagery most effectively."
  },
  {
    "objectID": "week7.html#reflections",
    "href": "week7.html#reflections",
    "title": "7  Week 7: Classification 2",
    "section": "7.5 Reflections",
    "text": "7.5 Reflections\nThis week’s content was quite technical, covering both advanced classifier methods and indicators for accuracy assessment (although I’ve learnt the concept of confusion matrix in accuracy assessment before in a module using machine learning). Nonetheless, it was exciting to try out landcover classification on GEE in the practical. While there was much room for improvement, I am excited to experiment with different methods in the future and understand how to optimally classify landcover.\nHowever, one slight concern I have is how technical remote sensing jargon can get in academic articles, but I think the only way is to slowly read more and be exposed to different methodologies.\n\n\n\n\nBarsi, Á., Zs. Kugler, I. László, Gy. Szabó, and H. M. Abdulmutalib. 2018. “ACCURACY DIMENSIONS IN REMOTE SENSING.” The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences XLII-3 (April): 61–67. https://doi.org/10.5194/isprs-archives-XLII-3-61-2018.\n\n\nFernández-García, Víctor, Elena Marcos, José Manuel Fernández-Guisuraga, Alfonso Fernández-Manso, Carmen Quintano, Susana Suárez-Seoane, and Leonor Calvo. 2021. “Multiple Endmember Spectral Mixture Analysis (MESMA) Applied to the Study of Habitat Diversity in the Fine-Grained Landscapes of the Cantabrian Mountains.” Remote Sensing 13 (5): 979. https://doi.org/10.3390/rs13050979.\n\n\nHerold, M., M. E. Gardner, and D. A. Roberts. 2003. “Spectral Resolution Requirements for Mapping Urban Areas.” IEEE Transactions on Geoscience and Remote Sensing 41 (9): 1907–19. https://doi.org/10.1109/TGRS.2003.815238.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Chapter 12 Statistical Learning | Geocomputation with R. https://r.geocompx.org/spatial-cv.html.\n\n\nMacLachlan, Andrew, Gareth Roberts, Eloise Biggs, and Bryan Boruff. 2017. “Subpixel Land-Cover Classification for Improved Urban Area Estimates Using Landsat.” International Journal of Remote Sensing 38 (20): 5763–92. https://doi.org/10.1080/01431161.2017.1346403.\n\n\nPhinn, S., M. Stanford, P. Scarth, A. T. Murray, and P. T. Shyy. 2002. “Monitoring the Composition of Urban Environments Based on the Vegetation-Impervious Surface-Soil (VIS) Model by Subpixel Analysis Techniques.” International Journal of Remote Sensing 23 (20): 4131–53. https://doi.org/10.1080/01431160110114998.\n\n\nPlaza, A., P. Martinez, R. Perez, and J. Plaza. 2002. “Spatial/Spectral Endmember Extraction by Multidimensional Morphological Operations.” IEEE Transactions on Geoscience and Remote Sensing 40 (9): 2025–41. https://doi.org/10.1109/TGRS.2002.802494.\n\n\nVarshney, Avnish, and Edida Rajesh. 2014. “A Comparative Study of Built-up Index Approaches for Automated Extraction of Built-up Regions From Remote Sensing Data.” Journal of the Indian Society of Remote Sensing 42 (3): 659–63. https://doi.org/10.1007/s12524-013-0333-9."
  },
  {
    "objectID": "week8.html",
    "href": "week8.html",
    "title": "8  Week 8: Temperature and Policy",
    "section": "",
    "text": "Learn how to analyse temperature across urban areas along both spatial and time scales"
  },
  {
    "objectID": "week8.html#summary-of-key-concepts",
    "href": "week8.html#summary-of-key-concepts",
    "title": "8  Week 8: Temperature and Policy",
    "section": "8.2 Summary of Key Concepts",
    "text": "8.2 Summary of Key Concepts\nWe first look at the causes of the Urban Heat Island Effect, its impacts, and then look at how it relates to global and local policies.\n\n8.2.1 Causes of Urban Heat Island Effect\nUrban areas are of higher temperatures, mainly due to 2 factors:\n\nMore dark surfaces that retain heat\nLess vegetation cooling the environment\n\nOther factors:\n\nLow Sky View Factor\nAir speed, cloud cover, cyclic solar radiation, building material and athropogenic energy\n\n\n\n\nImage illustrating Urban Heat Island Effect.\n\n\nSource: (Skeptical Science, n.d.).\n\n\n8.2.2 Costs of Urban Heat Island\n\nSocial\n\nHeat-related excess mortality of 1344 people in Ahmedabad’s 2010 Heatwave (Azhar et al. 2014).\n\nUrban geometry can contribute to heat islands and intra-urban temperature differences (eg. up to 6 degree in Delhi) (Yadav and Sharma 2018).\n\nHeat-associated deaths per year show an increasing trend in Phoenix, Arizona (Baker and Berisha 2021).\n\nEnvironmental\n\nPositive feedback loop as more water and electricity will be consumed to cool residents in high temperatures, and this contributes to further temperature increases.\n1°F increase in daily low temperatures associated with 290 gallons increase an average monthly usage of water for a typical single-family unit (Guhathakurta and Gober 2007).\nPeak electricity demand increases between 0.45 and 4.6% per degree of ambient temperature rise, corresponding to a penalty of about 21W per degree of temperature rise per person (Santamouris et al. 2015)\n\nEconomic\n\nMelbourne has assessed the cost of Urban Heat Island effect specifically (Raalte et al. 2012)\n\nEstimated AUD$300 million cost, of which $282 million are health costs\n\nUHI will result in GDP loss under different Green House Gas scenarios, however the specfic effects of UHI has been excluded in Global Climate Change (GCC) scenarios (Estrada, Botzen, and Tol 2017)\n\n\n\n\n8.2.3 Global Policy Documents/ Goals related to UHI\n\nNew Urban Agenda: standards and principles for planning construction, development, management and urban improvement (“The New Urban Agenda,” n.d.)\n\nRelated to points 37, 54, 79\n\nSustainable Development Goals (SDGs): targets with quantifiable indicators for monitoring purposes (“THE 17 GOALS | Sustainable Development,” n.d.)\n\nGoal 11 but no direct mention\n\nCOP26 (“UN Climate Change Conference (COP26) at the SEC  Glasgow 2021,” n.d.)\n\nReleased a Beat the Heat Handbook\n\n\n\n\n8.2.4 Policy Resources\n\n8.2.4.1 Beat the Heat Handbook Case Studies\n\nSuperblocks\nMedellin Green Corridors\nTurn Down the Heat Strategy and Action Plan 2018 (Sydney)\nChicago 1995 Heatwave\n\n\n\n8.2.4.2 Metropolitan UHI Reduction Strategies\nLondon Plan\nSingapore Master Plan\n\nJust a comment on the Open Space Provision by the Urban Redevelopment Authority requiring an open space plot at a rate of 4.05 sqm of open space for every 56sqm of gross floor area:\n\nThe provision applies to landed housing development clusters, which in practice take up very little space in Singapore owing to how uncommon they are.\nA more representative guideline would be how new Housing Development Board (HDB) developments must have a surrounding area of greenery that is 4.5 times the built-up area. HDB policies are more representative of Singapore’s policies as 80% of Singaporeans live in HDB’s public housing developments and occupy much more space than landed housing development clusters in Singapore."
  },
  {
    "objectID": "week8.html#summary-of-practical-content",
    "href": "week8.html#summary-of-practical-content",
    "title": "8  Week 8: Temperature and Policy",
    "section": "8.3 Summary of Practical Content",
    "text": "8.3 Summary of Practical Content\nThis week’s practical focuses on extracting temperature data from satellite data, and creating outputs that analyse it in spatial and time scales. For this practical, I focused on my home country Singapore, to understand spatial variations in temperature. I was unable to work on the Heat Index section of the practical due to time constraints, but will try to do so and update this learning diary with it in the future after assessment.\n\n8.3.1 Methodology to extract temperature per spatial unit\n\nLoad spatial data\nLoad temperature datasets (MODIS, Landsat etc)\n\nCollection\nFilter for standard stuff (date range, area of interest, cloud cover)\n\nReduce the image\n\nMedian: ee.Reducer.mean()\nor deciles: ee.Reducer.percentile([10, 20, 30, 40, 50, 60, 70, 80, 90])\n\nPlot temperature timeseries\nZonal statistics\n\n.reduceRegions() for Landsat data\nui.Chart.image.seriesByRegion() by lower level spatial data for MODIS data\n\nOutput shapefile\n\n\n\n8.3.2 Temperature Outputs of Singapore\nFirstly, we looked at the timeseries data of Singapore’s temperature, from February to September 2022. \nThe low temperature in May is surprising as it rarely gets that cold in Singapore, but might have been due to inter-monsoon conditions and intense rainfall then.\nPractical outputs:\n\n\n\n\n\n\nSatellite Imagery for Singapore\n\n\n\n\n\n\n\n\n\nSG Landsat\n\n\n\n\n\n\n\n\n\nSG MODIS\n\n\n\n\n\n\n\n\n\nSG spatial\n\n\n\n\n\n\nAnalysis of Singapore’s temperature from Landsat, MODIS and spatial zones output\n\n\n\nComparing and reflecting the various outputs from this practical:\n\nSimilarities:\n\nAll outputs are similar in reflecting the high temperatures on the Western side of Singapore, which makes sense as the industrial areas are concentrated in the west, such as Tuas Industrial Estate and Jurong Island which houses Singapore’s petrochemical industries\nThe Landsat and MODIS outputs are similar in showing some higher temperatures in the Eastern side too, probably due to the presence of Changi Airport there.\nThe central area is cooler due to the presence of the Central Water Catchment which is an area containing several reservoirs and surrounded by nature reserves.\n\nDifferences:\n\nThe Landsat output appears more refined compared to the coarse MODIS output.\nThe spatial units in the zonal statistics output are arbitrarily drawn and this might be due to the use of the administrative boundaries found in GEE. As a Singaporean, these boundaries frankly do not even make any sense to me. I would redo this section with perhaps Singapore’s 2019 planning area boundaries.\n\n\nNonetheless. this was an interesting application of the content learnt in this remote sensing module to a place that is close to my heart. I would like to experiment with data of different spatial resolutions too. I could have tried with a different date range, such as covering the entirety of a year, as Singapore is less affected by seasonal differences as a equatorial tropical country.\nAnother way this could be applied is to flood risk or pollution. All these reflect a certain degree of physical/ environmental vulnerability, and perhaps could be combined with social vulnerability (i.e. socio-economic status) such as the Future Heat Events and Social Vulnerability 2018 Map made by the Geospatial Research, Analysis, and Services Program (GRASP) team under the Agency of Toxic Substances and Disease Registry (ATSDR) in the US."
  },
  {
    "objectID": "week8.html#application-of-key-concepts-and-skills",
    "href": "week8.html#application-of-key-concepts-and-skills",
    "title": "8  Week 8: Temperature and Policy",
    "section": "8.4 Application of Key Concepts and Skills",
    "text": "8.4 Application of Key Concepts and Skills\nThe ability to use remotely sensed data for to map temperatures along spatio-temporal scales is very useful, and when combined with other remotely sensed data (e.g. Normalised Difference Moisture Index, Normalized Difference Water Index or urban structure/ landcover) or socio-economic data such health incidents or census data. The following studies are all various applications of remotely-sensed temperature data, combined with various data sources to produce some sort of heat vulnerability map (Méndez-Lázaro et al. 2018; Meftahi et al. 2022; Lee and Brown 2022; Räsänen et al. 2019). They all use Landsat 8 Band 10 Thermal Infrared as temperature inputs in their research. (Méndez-Lázaro et al. 2018) are of interest as they combine the temperature data with variables from census data to illustrate social vulnerability to heat, and ultimately produce the following Heat Vulnerability Index map of San Juan, Puerto Rico:\n\n\n\nHeat Vulnerability Index Map of San Juan, Puerto Rico. Source: (Méndez-Lázaro et al. 2018)\n\n\nLee and Brown’s work (2022) are also interesting as they combine temperature data with vector data on heat-related incidents, as well as socio-economic variables from census data. They found that the negative effects of thermal environments on human health were higher in areas with a high percentage of impervious surface, population over 65 years, non-white people, no high-school diploma or unemployment. These results can then be used for implementing targeted local intervention efforts at vulnerable areas and groups.\n\n\n\nHeat vulnerability map and spatial distribution of heat-related EMS incidents for census block groups. Source: (Lee and Brown 2022).\n\n\nIn view of climate change and how heatwaves during summer seasons can be more intense now and in the future, more cities should embark on similar studies of vulnerability, combining temperature data from Landsat 8 images with socio-economic data to assess the vulnerability of local areas and communities to heat-related illnesses or deaths. This allows local government to provide targeted resources for those who need it most."
  },
  {
    "objectID": "week8.html#reflections",
    "href": "week8.html#reflections",
    "title": "8  Week 8: Temperature and Policy",
    "section": "8.5 Reflections",
    "text": "8.5 Reflections\nThis week’s practical on extracting temperature data in GEE has been useful in seeing how we can do so practically, which is an extension of what we know remote sensing is capable of. It is eye-opening to see it in practice.\nWe have also built on what we saw in week 4 regarding policy and how the various groups in the module suggested using remotely sensed data for various policy applications, to see how what we’ve learnt in this module can be applied in policymaking. All this is certainly very exciting from a policymaking perspective, that so many new sources of data can be harnessed to improve the knowledge base for policymaking and bring real benefits to citizens all over the world.\nHowever, a real concern is the capability of municipal governments globally to harness the potential of remotely sensed data. Not all local governments have a GIS analyst, much less a GIS team to carry out such analyses. One suggestion is that practicals and methodologies to reproduce such heat vulnerability maps (or other vulnerability maps in relation to environmental hazards like pollution) can be openly available on the Internet, using openly available software and data so as to lower the barriers of entry for this field. This can allow more cities to fully utilise the data available to them for the benefit of residents.\n\n\n\n\nAzhar, Gulrez Shah, Dileep Mavalankar, Amruta Nori-Sarma, Ajit Rajiva, Priya Dutta, Anjali Jaiswal, Perry Sheffield, Kim Knowlton, and Jeremy J Hess. 2014. “Heat-Related Mortality in India: Excess All-Cause Mortality Associated with the 2010 Ahmedabad Heat Wave.” PloS One 9 (3): e91831.\n\n\nBaker, Tianna, and Vjollca Berisha. 2021. “2021 Heat Deaths.” https://www.maricopa.gov/DocumentCenter/View/74257/Final-2021-Heat-Deaths#:~:text=338%20heat%2Dassociated%20deaths%20were,a%2069.8%25%20increase%20from%202019.&text=The%20proportion%20of%20indoor%20heat,also%20been%20increasing%20each%20year.\n\n\nEstrada, Francisco, W. J. Wouter Botzen, and Richard S. J. Tol. 2017. “A Global Economic Assessment of City Policies to Reduce Climate Change Impacts.” Nature Climate Change 7 (6): 403–6. https://doi.org/10.1038/nclimate3301.\n\n\nGuhathakurta, Subhrajit, and Patricia Gober. 2007. “The Impact of the Phoenix Urban Heat Island on Residential Water Use.” Journal of the American Planning Association 73 (3): 317–29.\n\n\nLee, Kanghyun, and Robert D. Brown. 2022. “Effects of Urban Landscape and Sociodemographic Characteristics on Heat-Related Health Using Emergency Medical Service Incidents.” International Journal of Environmental Research and Public Health 19 (3): 1287. https://doi.org/10.3390/ijerph19031287.\n\n\nMeftahi, Maryam, Masoud Monavari, Mirmasoud Kheirkhah Zarkesh, Alireza Vafaeinejad, and Ali Jozi. 2022. “Achieving Sustainable Development Goals Through the Study of Urban Heat Island Changes and Its Effective Factors Using Spatio-Temporal Techniques: The Case Study (Tehran City).” Natural Resources Forum 46 (1): 88–115. https://doi.org/10.1111/1477-8947.12245.\n\n\nMéndez-Lázaro, Pablo, Frank E. Muller-Karger, Daniel Otis, Matthew J. McCarthy, and Ernesto Rodríguez. 2018. “A Heat Vulnerability Index to Improve Urban Public Health Management in San Juan, Puerto Rico.” International Journal of Biometeorology 62 (5): 709–22. https://doi.org/10.1007/s00484-017-1319-z.\n\n\nRaalte, Lucas van, Michael Nolan, Praveen Thakur, Simon Xue, and Nicki Parker. 2012. “Economic Assessment of the Urban Heat Island Effect.”\n\n\nRäsänen, Aleksi, this link will open in a new window Link to external site, Kimmo Heikkinen, Noora Piila, and Sirkku Juhola. 2019. “Zoning and Weighting in Urban Heat Island Vulnerability and Risk Mapping in Helsinki, Finland.” Regional Environmental Change 19 (5): 1481–93. https://doi.org/10.1007/s10113-019-01491-x.\n\n\nSantamouris, M., C. Cartalis, A. Synnefa, and D. Kolokotsa. 2015. “On the Impact of Urban Heat Island and Global Warming on the Power Demand and Electricity Consumption of BuildingsA Review.” Energy and Buildings, Renewable Energy Sources and Healthy Buildings, 98 (July): 119–24. https://doi.org/10.1016/j.enbuild.2014.09.052.\n\n\nSkeptical Science. n.d. “DENIAL101x 2.4.2 Urban Heat Island.” https://skepticalscience.com/graphics.php?g=251.\n\n\n“THE 17 GOALS | Sustainable Development.” n.d. https://sdgs.un.org/goals.\n\n\n“The New Urban Agenda.” n.d. https://habitat3.org/the-new-urban-agenda/.\n\n\n“UN Climate Change Conference (COP26) at the SEC  Glasgow 2021.” n.d. https://ukcop26.org/.\n\n\nYadav, Neha, and Chhemendra Sharma. 2018. “Spatial Variations of Intra-City Urban Heat Island in Megacity Delhi.” Sustainable Cities and Society 37: 298–306."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Azhar, Gulrez Shah, Dileep Mavalankar, Amruta Nori-Sarma, Ajit Rajiva,\nPriya Dutta, Anjali Jaiswal, Perry Sheffield, Kim Knowlton, and Jeremy J\nHess. 2014. “Heat-Related Mortality in India: Excess All-Cause\nMortality Associated with the 2010 Ahmedabad Heat Wave.” PloS\nOne 9 (3): e91831.\n\n\nBaker, Tianna, and Vjollca Berisha. 2021. “2021 Heat\nDeaths.” https://www.maricopa.gov/DocumentCenter/View/74257/Final-2021-Heat-Deaths#:~:text=338%20heat%2Dassociated%20deaths%20were,a%2069.8%25%20increase%20from%202019.&text=The%20proportion%20of%20indoor%20heat,also%20been%20increasing%20each%20year.\n\n\nBarsi, Á., Zs. Kugler, I. László, Gy. Szabó, and H. M. Abdulmutalib.\n2018. “ACCURACY DIMENSIONS IN REMOTE SENSING.” The\nInternational Archives of the Photogrammetry, Remote Sensing and Spatial\nInformation Sciences XLII-3 (April): 61–67. https://doi.org/10.5194/isprs-archives-XLII-3-61-2018.\n\n\nBoone, Randall B., Simon J. Thirgood, and J. Grant C. Hopcraft. 2006.\n“Serengeti Wildebeest Migratory Patterns Modeled from Rainfall and\nNew Vegetation Growth.” Ecology 87 (8): 1987–94. https://www.jstor.org/stable/20069184.\n\n\nBuiten, H. J., and B. van Putten. 1997. “Quality Assessment of\nRemote Sensing Image Registration  Analysis and Testing of\nControl Point Residuals.” ISPRS Journal of Photogrammetry and\nRemote Sensing 52 (2): 57–73. https://doi.org/10.1016/S0924-2716(97)83001-8.\n\n\nChuvieco, Emilio, and Russell G. Congalton. 1989. “Application of\nRemote Sensing and Geographic Information Systems to Forest Fire Hazard\nMapping.” Remote Sensing of Environment 29 (2): 147–59.\nhttps://doi.org/10.1016/0034-4257(89)90023-0.\n\n\nCorcione, Valeria, Andrea Buono, Ferdinando Nunziata, and Maurizio\nMigliaccio. 2021. “A Sensitivity Analysis on the Spectral\nSignatures of Low-Backscattering Sea Areas in Sentinel-1 SAR\nImages.” Remote Sensing 13 (6): 1183. https://doi.org/10.3390/rs13061183.\n\n\nDegerickx, Jeroen, Martin Hermy, and Ben Somers. 2020. “Mapping\nFunctional Urban Green Types Using High Resolution Remote Sensing\nData.” Sustainability 12 (5): 2144. https://doi.org/10.3390/su12052144.\n\n\nEstrada, Francisco, W. J. Wouter Botzen, and Richard S. J. Tol. 2017.\n“A Global Economic Assessment of City Policies to Reduce Climate\nChange Impacts.” Nature Climate Change 7 (6): 403–6. https://doi.org/10.1038/nclimate3301.\n\n\nFaridatul, Mst Ilme, and Bayes Ahmed. 2020. “Assessing\nAgricultural Vulnerability to Drought in a Heterogeneous Environment: A\nRemote Sensing-Based Approach.” Remote Sensing 12 (20):\n3363. https://doi.org/10.3390/rs12203363.\n\n\nFarwell, Laura S., David Gudex-Cross, Ilianna E. Anise, Michael J.\nBosch, Ashley M. Olah, Volker C. Radeloff, Elena Razenkova, et al. 2021.\n“Satellite Image Texture Captures Vegetation Heterogeneity and\nExplains Patterns of Bird Richness.” Remote Sensing of\nEnvironment 253 (February): 112175. https://doi.org/10.1016/j.rse.2020.112175.\n\n\nFensholt, Rasmus, and Simon R. Proud. 2012. “Evaluation of Earth\nObservation Based Global Long Term Vegetation Trends \nComparing GIMMS and MODIS Global NDVI Time Series.” Remote\nSensing of Environment 119 (April): 131–47. https://doi.org/10.1016/j.rse.2011.12.015.\n\n\nFernández-García, Víctor, Elena Marcos, José Manuel Fernández-Guisuraga,\nAlfonso Fernández-Manso, Carmen Quintano, Susana Suárez-Seoane, and\nLeonor Calvo. 2021. “Multiple Endmember Spectral Mixture Analysis\n(MESMA) Applied to the Study of Habitat Diversity in the Fine-Grained\nLandscapes of the Cantabrian Mountains.” Remote Sensing\n13 (5): 979. https://doi.org/10.3390/rs13050979.\n\n\nFuladlu, Kamyar, and Haşim Altan. 2021. “Examining Land Surface\nTemperature and Relations with the Major Air Pollutants: A Remote\nSensing Research in Case of Tehran.” Urban Climate 39\n(September): 100958. https://doi.org/10.1016/j.uclim.2021.100958.\n\n\nGuhathakurta, Subhrajit, and Patricia Gober. 2007. “The Impact of\nthe Phoenix Urban Heat Island on Residential Water\nUse.” Journal of the American Planning Association 73\n(3): 317–29.\n\n\nHall-Beyer, Mryka. 2017. “GLCM Texture: A Tutorial v. 3.0 March\n2017.”\n\n\nHansen, M. C., P. V. Potapov, R. Moore, M. Hancher, S. A. Turubanova, A.\nTyukavina, D. Thau, et al. 2013. “High-Resolution Global Maps of\n21st-Century Forest Cover Change.” Science 342 (6160):\n850–53. https://doi.org/10.1126/science.1244693.\n\n\nHaralick, Robert M., K. Shanmugam, and Its’Hak Dinstein. 1973.\n“Textural Features for Image Classification.” IEEE\nTransactions on Systems, Man, and Cybernetics SMC-3 (6): 610–21. https://doi.org/10.1109/TSMC.1973.4309314.\n\n\nHerold, M., M. E. Gardner, and D. A. Roberts. 2003. “Spectral\nResolution Requirements for Mapping Urban Areas.” IEEE\nTransactions on Geoscience and Remote Sensing 41 (9): 1907–19. https://doi.org/10.1109/TGRS.2003.815238.\n\n\nHuth, Juliane, Claudia Kuenzer, Thilo Wehrmann, Steffen Gebhardt, Vo\nQuoc Tuan, and Stefan Dech. 2012. “Land Cover and Land Use\nClassification with TWOPAC: Towards Automated Processing for Pixel- and\nObject-Based Image Classification.” Remote Sensing 4\n(9): 2530–53. https://doi.org/10.3390/rs4092530.\n\n\nJensen, John R. 2015. Introductory Digital Image Processing: A\nRemote Sensing Perspective. Pearson Education, Incorporated.\n\n\nJuergens, Carsten, and M. Fabian Meyer-Heß. 2022. “Experimental\nAnalysis of Geo-Spatial Data to Evaluate Urban Greenspace: A Case Study\nin Dortmund, Germany.” KN - Journal of Cartography and\nGeographic Information 72 (2): 153–71. https://doi.org/10.1007/s42489-022-00107-5.\n\n\nKlonus, Sascha, and Manfred Ehlers. 2009. “2009 12th International\nConference on Information Fusion.” In, 1409–16.\n\n\nLee, Kanghyun, and Robert D. Brown. 2022. “Effects of Urban\nLandscape and Sociodemographic Characteristics on Heat-Related Health\nUsing Emergency Medical Service Incidents.” International\nJournal of Environmental Research and Public Health 19 (3): 1287.\nhttps://doi.org/10.3390/ijerph19031287.\n\n\nLi, Dan, Yinghai Ke, Huili Gong, and Xiaojuan Li. 2015.\n“Object-Based Urban Tree Species Classification Using Bi-Temporal\nWorldView-2 and WorldView-3 Images.” Remote Sensing 7\n(12): 16917–37. https://doi.org/10.3390/rs71215861.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Chapter\n12 Statistical Learning | Geocomputation with R. https://r.geocompx.org/spatial-cv.html.\n\n\nMacLachlan, Andrew, Eloise Biggs, Gareth Roberts, and Bryan Boruff.\n2017. “Urban Growth Dynamics in Perth, Western Australia: Using\nApplied Remote Sensing for Sustainable Future Planning.”\nLand 6 (1): 9. https://doi.org/10.3390/land6010009.\n\n\nMacLachlan, Andrew, Gareth Roberts, Eloise Biggs, and Bryan Boruff.\n2017. “Subpixel Land-Cover Classification for Improved Urban Area\nEstimates Using Landsat.” International Journal of Remote\nSensing 38 (20): 5763–92. https://doi.org/10.1080/01431161.2017.1346403.\n\n\nMeftahi, Maryam, Masoud Monavari, Mirmasoud Kheirkhah Zarkesh, Alireza\nVafaeinejad, and Ali Jozi. 2022. “Achieving Sustainable\nDevelopment Goals Through the Study of Urban Heat Island Changes and Its\nEffective Factors Using Spatio-Temporal Techniques: The Case Study\n(Tehran City).” Natural Resources Forum 46 (1): 88–115.\nhttps://doi.org/10.1111/1477-8947.12245.\n\n\nMéndez-Lázaro, Pablo, Frank E. Muller-Karger, Daniel Otis, Matthew J.\nMcCarthy, and Ernesto Rodríguez. 2018. “A Heat Vulnerability Index\nto Improve Urban Public Health Management in San Juan, Puerto\nRico.” International Journal of Biometeorology 62 (5):\n709–22. https://doi.org/10.1007/s00484-017-1319-z.\n\n\nNeyns, Robbe, and Frank Canters. 2022. “Mapping of Urban\nVegetation with High-Resolution Remote Sensing: A Review.”\nRemote Sensing 14 (4): 1031. https://doi.org/10.3390/rs14041031.\n\n\nNovak, Kurt. 1992. “Rectification of Digital Imagery.”\nPHOTOGRAMMETRIC ENGINEERING.\n\n\nPhinn, S., M. Stanford, P. Scarth, A. T. Murray, and P. T. Shyy. 2002.\n“Monitoring the Composition of Urban Environments Based on the\nVegetation-Impervious Surface-Soil (VIS) Model by Subpixel Analysis\nTechniques.” International Journal of Remote Sensing 23\n(20): 4131–53. https://doi.org/10.1080/01431160110114998.\n\n\nPhiri, Darius, and Justin Morgenroth. 2017. “Developments in\nLandsat Land Cover Classification Methods: A Review.” Remote\nSensing 9 (9): 967. https://doi.org/10.3390/rs9090967.\n\n\nPinto, Daniele Gutterres, Denise Cybis Fontana, Genei Antonio Dalmago,\nElizandro Fochesatto, Matheus Boni Vicari, Carolina Bremm, Gilberto\nRocca da Cunha, Jorge Alberto de Gouvêa, and Anderson Santi. 2017.\n“Correlations Between Spectral and Biophysical Data Obtained in\nCanola Canopy Cultivated in the Subtropical Region of Brazil.”\nPesquisa Agropecuária Brasileira 52 (10): 825–32. https://doi.org/10.1590/s0100-204x2017001000001.\n\n\nPlaza, A., P. Martinez, R. Perez, and J. Plaza. 2002.\n“Spatial/Spectral Endmember Extraction by Multidimensional\nMorphological Operations.” IEEE Transactions on Geoscience\nand Remote Sensing 40 (9): 2025–41. https://doi.org/10.1109/TGRS.2002.802494.\n\n\nPratt, William. 2013. Introduction to Digital Image Processing.\nBoca Raton: CRC Press. https://learning.oreilly.com/library/view/introduction-to-digital/9781482216691/.\n\n\nQi, Shuhua, Bin Song, Chong Liu, Peng Gong, Jin Luo, Meinan Zhang, and\nTianwei Xiong. 2022. “Bamboo Forest Mapping in China Using the\nDense Landsat 8 Image Archive and Google Earth Engine.”\nRemote Sensing 14 (3): 762. https://doi.org/10.3390/rs14030762.\n\n\nRaalte, Lucas van, Michael Nolan, Praveen Thakur, Simon Xue, and Nicki\nParker. 2012. “Economic Assessment of the Urban Heat Island\nEffect.”\n\n\nRäsänen, Aleksi, this link will open in a new window Link to external\nsite, Kimmo Heikkinen, Noora Piila, and Sirkku Juhola. 2019.\n“Zoning and Weighting in Urban Heat Island Vulnerability and Risk\nMapping in Helsinki, Finland.” Regional Environmental\nChange 19 (5): 1481–93. https://doi.org/10.1007/s10113-019-01491-x.\n\n\nRen, Zhibin, Ruiliang Pu, Haifeng Zheng, Dan Zhang, and Xingyuan He.\n2017. “Spatiotemporal Analyses of Urban Vegetation Structural\nAttributes Using Multitemporal Landsat TM Data and Field\nMeasurements.” Annals of Forest Science 74 (3): 1–14. https://doi.org/10.1007/s13595-017-0654-x.\n\n\nSantamouris, M., C. Cartalis, A. Synnefa, and D. Kolokotsa. 2015.\n“On the Impact of Urban Heat Island and Global Warming on the\nPower Demand and Electricity Consumption of BuildingsA\nReview.” Energy and Buildings, Renewable Energy Sources\nand Healthy Buildings, 98 (July): 119–24. https://doi.org/10.1016/j.enbuild.2014.09.052.\n\n\nShafizadeh-Moghadam, Hossein, Morteza Khazaei, Seyed Kazem Alavipanah,\nand Qihao Weng. 2021. “Google Earth Engine for Large-Scale Land\nUse and Land Cover Mapping: An Object-Based Classification Approach\nUsing Spectral, Textural and Topographical Factors.”\nGIScience & Remote Sensing 58 (6): 914–28. https://doi.org/10.1080/15481603.2021.1947623.\n\n\nShahtahmassebi, Amir Reza, Chenlu Li, Yifan Fan, Yani Wu, Yue lin, Muye\nGan, Ke Wang, Arunima Malik, and George Alan Blackburn. 2021.\n“Remote Sensing of Urban Green Spaces: A Review.” Urban\nForestry & Urban Greening 57 (January): 126946. https://doi.org/10.1016/j.ufug.2020.126946.\n\n\nSkeptical Science. n.d. “DENIAL101x 2.4.2 Urban Heat\nIsland.” https://skepticalscience.com/graphics.php?g=251.\n\n\nTassi, Andrea, and Marco Vizzari. 2020. “Object-Oriented LULC\nClassification in Google Earth Engine Combining SNIC, GLCM, and Machine\nLearning Algorithms.” Remote Sensing 12 (22): 3776. https://doi.org/10.3390/rs12223776.\n\n\n“THE 17 GOALS | Sustainable Development.” n.d. https://sdgs.un.org/goals.\n\n\n“The New Urban Agenda.” n.d. https://habitat3.org/the-new-urban-agenda/.\n\n\nTucker, Compton J., Jorge E. Pinzon, Molly E. Brown, Daniel A. Slayback,\nEdwin W. Pak, Robert Mahoney, Eric F. Vermote, and Nazmi El Saleous.\n2005. “An Extended AVHRR 8-Km NDVI Dataset Compatible\nwith MODIS and SPOT Vegetation NDVI Data.” International\nJournal of Remote Sensing 26 (20): 4485–98. https://doi.org/10.1080/01431160500168686.\n\n\n“UN Climate Change Conference (COP26) at the SEC \nGlasgow 2021.” n.d. https://ukcop26.org/.\n\n\nVarshney, Avnish, and Edida Rajesh. 2014. “A Comparative Study of\nBuilt-up Index Approaches for Automated Extraction of Built-up Regions\nFrom Remote Sensing Data.” Journal of the Indian Society of\nRemote Sensing 42 (3): 659–63. https://doi.org/10.1007/s12524-013-0333-9.\n\n\nWang, Kepu, Tiejun Wang, and Xuehua Liu. 2019. “A Review:\nIndividual Tree Species Classification Using Integrated Airborne LiDAR\nand Optical Imagery with a Focus on the Urban Environment.”\nForests 10 (1): 1. https://doi.org/10.3390/f10010001.\n\n\nWen, Dawei, Xin Huang, Hui Liu, Wenzhi Liao, and Liangpei Zhang. 2017.\n“Semantic Classification of Urban Trees Using Very High Resolution\nSatellite Imagery.” IEEE Journal of Selected Topics in\nApplied Earth Observations and Remote Sensing 10 (4): 1413–24. https://doi.org/10.1109/JSTARS.2016.2645798.\n\n\nWolberg, George. 1990. Digital Image Warping | Wiley. New York:\nJohn Wiley- IEEE Computer Society. https://www.wiley.com/en-us/Digital+Image+Warping-p-9780818689444.\n\n\nYadav, Neha, and Chhemendra Sharma. 2018. “Spatial Variations of\nIntra-City Urban Heat Island in Megacity Delhi.” Sustainable\nCities and Society 37: 298–306.\n\n\nZhang, Xiuying, Xuezhi Feng, and Hong Jiang. 2010.\n“Object-Oriented Method for Urban Vegetation Mapping Using IKONOS\nImagery.” International Journal of Remote Sensing 31\n(1): 177–96. https://doi.org/10.1080/01431160902882603."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "9  Module Summary",
    "section": "",
    "text": "After this module, I am grateful for the methods taught, on how to use SNAP and GEE and other skills, so as to use raster data for effective analysis. The learning curve felt very deep at times, but the guidance given in this module has made this learning process a lot more bearable. I am also more confident of my abilities in using remotely-sensed data, but I am also aware of how vast the remote sensing domain is and how much I can learn in this area. I hope I can be continually exposed to best practices in remote sensing and learning how I can use it better. But even if I am unable to do so in the future due to time constraints or just not using it in my job, I think this learning diary and Andy’s CASA0023 website was helpful in condensing what I learnt and can help in jogging my memory in the future too. I am glad that I took this module and hope future CASA students also have that opportunity.\nFor this module, I also worked on a group presentation with Atsumi, Eunyoung, Yi-Chien and Yifei. In the coursework scenario, we were applying to help a city improve compliance of their metropolitan development plans in adhering to and achieving compliance with global development goals / frameworks / agendas (e.g. New Urban Agenda, Sustainable Development Goals or the Sendai Framework for disaster risk reduction), within a budget of £500,000. We focused on Ahmedabad, India, and how they could incorporate remotely sensed data into local plans for heatwave monitoring and forecasting for slum populations so as to identify high-risk areas and people groups for intervention resources to be directed to. The presentation slides can be found here and the Github repo for the slides can be found here. Thank you for reading my remote sensing learning diary!"
  }
]